{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport nltk\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem import WordNetLemmatizer\nimport string\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom tensorflow import keras\nfrom keras.layers import Input, LSTM, Dense\nfrom keras.models import Model\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-23T09:22:39.035786Z","iopub.execute_input":"2022-12-23T09:22:39.036700Z","iopub.status.idle":"2022-12-23T09:22:45.692970Z","shell.execute_reply.started":"2022-12-23T09:22:39.036599Z","shell.execute_reply":"2022-12-23T09:22:45.691815Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\nstemmer = SnowballStemmer('english')\nstopwords = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:22:45.699054Z","iopub.execute_input":"2022-12-23T09:22:45.701872Z","iopub.status.idle":"2022-12-23T09:22:45.717444Z","shell.execute_reply.started":"2022-12-23T09:22:45.701831Z","shell.execute_reply":"2022-12-23T09:22:45.716149Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:22:45.722189Z","iopub.execute_input":"2022-12-23T09:22:45.724594Z","iopub.status.idle":"2022-12-23T09:22:46.036194Z","shell.execute_reply.started":"2022-12-23T09:22:45.724548Z","shell.execute_reply":"2022-12-23T09:22:46.035263Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"rawData = pd.read_csv('/kaggle/input/customer-support-on-twitter/twcs/twcs.csv')\ncompany = \"AppleSupport\"\nrawData.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:22:46.041563Z","iopub.execute_input":"2022-12-23T09:22:46.043821Z","iopub.status.idle":"2022-12-23T09:23:03.525558Z","shell.execute_reply.started":"2022-12-23T09:22:46.043781Z","shell.execute_reply":"2022-12-23T09:23:03.524595Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   tweet_id   author_id  inbound                      created_at  \\\n0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n\n                                                text response_tweet_id  \\\n0  @115712 I understand. I would like to assist y...                 2   \n1      @sprintcare and how do you propose we do that               NaN   \n2  @sprintcare I have sent several private messag...                 1   \n3  @115712 Please send us a Private Message so th...                 3   \n4                                 @sprintcare I did.                 4   \n\n   in_response_to_tweet_id  \n0                      3.0  \n1                      1.0  \n2                      4.0  \n3                      5.0  \n4                      6.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>author_id</th>\n      <th>inbound</th>\n      <th>created_at</th>\n      <th>text</th>\n      <th>response_tweet_id</th>\n      <th>in_response_to_tweet_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n      <td>@115712 I understand. I would like to assist y...</td>\n      <td>2</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n      <td>@sprintcare I have sent several private messag...</td>\n      <td>1</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n      <td>@115712 Please send us a Private Message so th...</td>\n      <td>3</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n      <td>@sprintcare I did.</td>\n      <td>4</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"rawData[rawData['author_id'].str.contains(company)].head(30)\n\ncompanyAnswers = rawData[rawData['author_id'].str.contains(company)].head(1000)\n\ncompanyAnswers.head(5)\n\nanswerTweets = []\nfor idx, t in companyAnswers[companyAnswers['author_id'].str.contains(company)].iterrows():\n     if not np.isnan(t['in_response_to_tweet_id']):\n \n        answerTweets.append(t)\n\nquestionTweets = []\n\nanswerTweets[0]['in_response_to_tweet_id']\n\nfor a in answerTweets:\n    question = rawData.loc[rawData['tweet_id'] == a['in_response_to_tweet_id']]\n    questionTweets.append(question['text'].to_string(index=False))\n\nfor idx, t in enumerate(answerTweets):\n    answerTweets[idx] = answerTweets[idx]['text']\n    \nprint(answerTweets[2])\nprint(questionTweets[2])\nprint(len(answerTweets))\nprint(len(questionTweets))","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:23:03.527211Z","iopub.execute_input":"2022-12-23T09:23:03.527881Z","iopub.status.idle":"2022-12-23T09:23:11.648093Z","shell.execute_reply.started":"2022-12-23T09:23:03.527833Z","shell.execute_reply":"2022-12-23T09:23:11.647098Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"@115855 Let's go to DM for the next steps. DM us here: https://t.co/GDrqU22YpT\n@AppleSupport Tried resetting my settings .. re...\n997\n997\n","output_type":"stream"}]},{"cell_type":"code","source":"qListTemp = []\naListTemp = []\n\nfor t in questionTweets:\n    t = re.sub('@[^\\s]+','',t)\n    t = re.sub('http[^\\s]+','',t)\n    qListTemp.append(t)\n    \nfor t in answerTweets:\n    t = re.sub('@[^\\s]+','',t)\n    t = re.sub('http[^\\s]+','',t)\n    aListTemp.append(t)\n\nquestionTweets = qListTemp\nanswerTweets = aListTemp\npairs = list(zip(questionTweets,answerTweets))\nprint(print(pairs[66]))","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:23:11.650243Z","iopub.execute_input":"2022-12-23T09:23:11.650852Z","iopub.status.idle":"2022-12-23T09:23:11.665033Z","shell.execute_reply.started":"2022-12-23T09:23:11.650812Z","shell.execute_reply":"2022-12-23T09:23:11.663907Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(' really needs to fix this update. My pho...', \" We're here to help with any issues you may having with performance. Let us know the exact iOS version to get started.\")\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"input_docs = []\ntarget_docs = []\ninput_tokens = set()\ntarget_tokens = set()\n\nfor tweet in pairs:\n    input_doc, target_doc = tweet[0], tweet[1] \n    input_docs.append(input_doc)\n\n    target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n\n    target_doc = '<START> ' + target_doc + ' <END>' \n    target_docs.append(target_doc)\n\n    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n        if token not in input_tokens:\n            input_tokens.add(token)\n    for token in target_doc.split():\n        if token not in target_tokens:\n            target_tokens.add(token)\n\ninput_tokens = sorted(list(input_tokens))\nprint(\"INPUT TOKENS\")\nprint(input_tokens)\n\ntarget_tokens = sorted(list(target_tokens))\nprint(\"TARGET TOKENS\")\nprint(target_tokens)\n\nnum_encoder_tokens = len(input_tokens)\nnum_decoder_tokens = len(target_tokens)\n\ninput_features_dict = dict([(token, i) for i, token in enumerate(input_tokens)])\ntarget_features_dict = dict([(token, i) for i, token in enumerate(target_tokens)])\n\nprint(\"INPUT FEATURES\")\nprint(input_features_dict)\n\nreverse_input_features_dict = dict((i, token) for token, i in input_features_dict.items())\nreverse_target_features_dict = dict((i, token) for token, i in target_features_dict.items())\n\nmax_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\nmax_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n\nencoder_input_data = np.zeros((len(input_docs), max_encoder_seq_length, num_encoder_tokens),dtype='float32')\ndecoder_input_data = np.zeros((len(input_docs), max_decoder_seq_length, num_decoder_tokens),dtype='float32')\ndecoder_target_data = np.zeros((len(input_docs), max_decoder_seq_length, num_decoder_tokens),dtype='float32')\n\nprint(\"encoder input\")\nprint(encoder_input_data)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:23:11.667145Z","iopub.execute_input":"2022-12-23T09:23:11.667615Z","iopub.status.idle":"2022-12-23T09:23:11.718534Z","shell.execute_reply.started":"2022-12-23T09:23:11.667578Z","shell.execute_reply":"2022-12-23T09:23:11.717579Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"INPUT TOKENS\n['!', '\"', '#', '$', '%', '&', '(', ')', '*', '+', ',', '-', '.', '/', '0', '000', '03', '1', '10', '100', '100335493202', '11', \"11'\", '12', '13', '14', '15', '15B150', '18', '1h', '1にあげたらTwitter少し見てるだけだし低電力モードなのに20パーへったぞ', '2', '20', '2010', '2011', '23', '256', '28', '2nd', '3', '30', '38', '3D', '3rd', '4', '42', '4times', '5', '5S', '5s', '6', '60', '6S', '6SPlus', '6s', '6sPlus', '7', '7plus', '8', '9TB', ':', ';', '=', '?', 'A', 'ACONTECENDO', 'AF', 'AFTER', 'AGAIN', 'AND', 'APPLE', 'AQUI', 'ASA', 'AT', 'Actualize', 'Add', 'After', 'AirPods', 'Akku', 'Aktivierung', 'Alguém', 'All', 'Already', 'Also', 'Although', 'Amma', 'And', 'Animal', 'Annnnnnd', 'Another', 'Any', 'Anyone', 'App', 'Apple', 'AppleCa', 'AppleWatch', 'Applewatch', 'At', 'Auto', 'Ayo', 'Ayúdame', 'BLUETOOTH', 'BRAND', 'BRO', 'BUTTON', 'Baje', 'Basically', 'Battery', 'Bec', 'Been', 'Benutzung', 'Bienvenida', 'Bl', 'Bluetoo', 'Bluetooth', 'Both', 'Bridgeport', 'Bro', 'But', 'C', 'CONSTANTLY', 'Ca', 'Calendar', 'Can', 'Cannot', 'Care', 'Case', 'Chall', 'Challenge', 'Chang', 'Chat', 'Checked', 'Cmo', 'Come', 'Congrats', 'Connect', 'Contacts', 'Cr', 'Cupertino', 'DL', 'DM', 'DMs', 'DOES', 'DOESN', 'Damn', 'Day', 'De', 'Dear', 'Deleted', 'Depende', 'Depois', 'Did', \"Didn't\", 'Disappointed', 'Do', 'Does', 'DolbyVision', 'Don', 'Downloaded', 'EVER', 'EVERYTIME', 'Either', 'El', 'Em', 'English', 'Eu', 'Even', 'Ever', 'Every', 'Everytime', 'Excuse', 'Eye', 'FI', 'FIX', 'FOCO', 'FUCK', 'FYI', 'Fail', 'Ffs', 'Fi', 'Fishing', 'Fix', 'Fixed', 'Folders', 'Followed', 'For', 'Freezing', 'Friday', 'GA', 'GOT', 'Germ', 'Get', 'Gmail', 'Go', 'God', 'Got', 'Great', 'H', 'HAPP', 'HELP', 'HEY', 'HOME', 'Has', 'Have', 'Hello', 'Help', 'Here', 'Hey', 'Heyyy', 'Hi', 'High', 'HighSierra', 'Hmm', 'Hoe', 'Hola', 'How', 'I', \"I'm\", \"I've\", 'ID', 'IOS', 'IOS11', 'IOSissues', 'IPhone', 'IS', 'IT', 'If', 'Ill', 'Im', 'Impossible', 'Installed', 'Ios', 'Ipad', 'Iphone', 'IphoneX', 'Is', 'It', \"It's\", 'Its', 'Jk', 'Just', 'KEEP', 'Keep', 'Keeps', 'Keyboard', 'Klucííí', 'LTE', 'Lacie', 'Landscape', 'Last', 'Latest', 'LiFE', 'Like', 'Listen', 'Lo', 'Location', 'Lockout', 'Lol', 'Love', 'MAC', 'ME', 'MMS', 'MY', 'Mac', 'MacBoo', 'MacBook', 'MacOS', 'MacPro', 'Man', 'Maybe', 'Min', 'Mine', 'Mmmmm', 'Mobile', 'More', 'Multitasking', 'Musi', 'Music', 'My', 'NEVER', 'NEW', 'NOW', 'Nachrichten', 'No', 'Nope', 'Not', 'Noted', 'Nothing', 'Novem', 'November', 'Now', 'Não', 'O', 'OK', 'ONLY', 'OTG', 'Oct', 'October', 'Oh', 'Ohh', 'Ok', 'Okay', 'Okey', 'Omg', 'On', 'Only', 'Open', 'Other', 'Overlapping', 'Oye', 'PHONE', 'PIOROU', 'PR', 'PT1', 'Pa', 'Paris', 'Ph', 'Phone', 'Pl', 'Pla', 'Please', 'Plus', 'Press', 'Pro', 'Problem', 'Progress', 'Q', 'Question', 'RT', 'Really', 'Restarting', 'SAME', 'SE', 'SMS', 'SY', 'Saf', 'Safari', 'Same', 'Saurabh', 'Scar', 'See', 'Seems', 'Sent', 'Series', 'Series1', 'Seriously', 'Should', 'Sierra', 'Since', 'Singapore', 'Siri', 'So', 'Sometimes', 'Sooooooo', 'Sorry', 'Sta', 'Standby', 'Steve', 'Still', 'Stop', 'Store', 'Support', 'T', 'THE', 'THIS', 'TIME', 'TO', 'TURN', 'TV', 'TYPE', 'Teally', 'Tengo', 'Terror', 'Tf', 'Thank', 'Thanks', 'That', 'The', 'These', 'This', 'TimeMachine', 'Tip', 'To', 'Today', 'Todos', 'Too', 'Top', 'Touch', 'Tried', 'Truly', 'Trying', 'Tudo', 'Twitter', 'Type', 'TÁ', 'Ummm', 'Unable', 'Update', 'Updated', 'Upgrade', 'Upgraded', 'Ur', 'Using', 'Version', 'Very', 'Videoshop', 'W', 'WHY', 'WORK', 'WTF', 'Wait', 'Wasn', 'Watch', 'WatchOS', 'We', 'Well', 'What', 'Whats', 'When', 'Where', 'Why', 'WiFi', 'Will', 'Won', 'Worked', 'Wow', 'Wro', 'Wtf', 'X', 'XXI', 'Y', 'Yay', 'Yayz', 'Yes', 'Yo', 'You', 'Youtube', 'Zumba', '[', '\\\\', ']', '^', '__email__', '`', 'a', 'able', 'abo', 'about', 'absolutely', 'ac', 'acc', 'access', 'acciden', 'account', 'acting', 'activity', 'actua', 'actual', 'actualiz', 'adapter', 'add', 'added', 'adding', 'address', 'adjust', 'admin', 'adress', 'aft', 'after', 'ago', 'ai', 'al', 'alarm', 'all', 'already', 'also', 'am', 'amazing', 'amount', 'amp', 'an', 'and', 'anno', 'annoying', 'another', 'answers', 'any', 'anymor', 'anymore', 'anyone', 'ap', 'app', 'apple', 'applem', 'approved', 'apps', 'appstore', 'appt', 'apresenta', 'ar', 'are', 'aren', 'arreglar', 'art', 'as', 'asking', 'at', 'attempts', 'atualizado', 'au', 'audio', 'auto', 'autocorrect', 'autocorrecting', 'available', 'avg', 'award', 'awful', 'b', 'ba', 'back', 'backed', 'backup', 'bana', 'bar', 'basically', 'bat', 'bateria', 'batte', 'batter', 'battery', 'bc', 'be', 'bec', 'became', 'becaus', 'because', 'becom', 'bee', 'been', 'bef', 'before', 'behaviour', 'bei', 'being', 'belie', 'believe', 'best', 'beta', 'billion', 'bitch', 'blank', 'blowing', 'bom', 'bonitos', 'boot', 'bose', 'both', 'bought', 'box', 'boxed', 'boxes', 'brain', 'bro', 'broadcast', 'broken', 'bu', 'bug', 'buggie', 'buggy', 'bugs', 'bullshit', 'burned', 'burning', 'but', 'button', 'buy', 'by', 'bypass', 'c', 'ca', 'cale', 'calendar', 'call', 'called', 'came', 'camera', 'can', \"can't\", 'cancel', 'cannot', 'cant', 'capital', 'card', 'casa', 'cassé', 'ce', 'center', 'centres', 'certai', 'chal', 'challenge', 'chan', 'change', 'changi', 'changing', 'character', 'charged', 'charger', 'charging', 'chat', 'chats', 'chatti', 'check', 'checked', 'clavier', 'cle', 'close', 'closed', 'cmon', 'co', 'collective', 'com', 'combi', 'come', 'coming', 'como', 'complain', 'complaining', 'complet', 'completed', 'completely', 'computer', 'con', 'conc', 'conectar', 'confirm', 'conne', 'connect', 'connected', 'connecter', 'connection', 'considering', 'consistent', 'consistently', 'consumes', 'consumo', 'consumpt', 'contact', 'contacts', 'contr', 'control', 'controls', 'convinc', 'cool', 'cost', 'couldn', \"couldn't\", 'couple', 'coverage', 'covered', 'crackli', 'crackling', 'crash', 'crashed', 'crashing', 'crazy', 'create', 'creates', 'cripple', 'cu', 'cual', 'cuando', 'currently', 'customer', 'cuts', 'cycle', 'd', 'da', 'damaged', 'damn', 'data', 'date', 'dating', 'day', 'days', 'de', 'dear', 'decided', 'decides', 'del', 'deleted', 'deleting', 'delivery', 'dementia', 'details', 'developper', 'diagno', 'dial', 'did', 'didn', 'died', 'dies', 'different', 'direct', 'disable', 'disappearing', 'disappointed', 'disfuncti', 'dm', 'do', 'docs', 'doe', 'does', 'doesn', \"doesn't\", 'doesnt', 'doing', 'don', \"don't\", 'done', 'doubt', 'down', 'downgrade', 'downl', 'download', 'downloaded', 'downloading', 'drain', 'draining', 'drains', 'drama', 'dropped', 'du', 'dumb', 'duplicated', 'dying', 'děláte', 'e', 'each', 'ear', 'earbuds', 'either', 'el', 'else', 'emai', 'email', 'emails', 'embarrassing', 'emojis', 'en', 'enable', 'entire', 'epilepsy', 'epıl', 'equipo', 'eras', 'erased', 'error', 'es', 'est', 'estão', 'et', 'etc', 'ev', 'even', 'ever', 'every', 'everytime', 'evry', 'example', 'excuse', 'expected', 'experiencing', 'expert', 'explain', 'explanatory', 'external', 'externe', 'extr', 'eye', 'f', 'fa', 'facing', 'fact', 'failed', 'failure', 'fait', 'fake', 'far', 'fast', 'fear', 'feature', 'features', 'fed', 'feel', 'feels', 'fehl', 'fetc', 'fetched', 'few', 'figure', 'figured', 'finally', 'find', 'fine', 'fix', 'fixed', 'fixing', 'fo', 'focu', 'focusing', 'folks', 'followed', 'following', 'for', 'force', 'forced', 'fot', 'fotos', 'fraud', 'freaking', 'free', 'freeze', 'freezes', 'freezin', 'freezing', 'fri', 'frnds', 'from', 'froze', 'frustrated', 'frustrating', 'fuccin', 'fuck', 'fucking', 'fucks', 'full', 'fully', 'functi', 'further', 'fuxking', 'g', 'get', 'gets', 'getting', 'gift', 'give', 'giving', 'glass', 'glitch', 'glitching', 'glitchy', 'go', 'god', 'going', 'gon', 'gone', 'gonna', 'good', 'googled', 'got', 'gotta', 'gr', 'great', 'green', 'grief', 'group', 'guess', 'guy', 'guys', 'h', 'ha', 'had', 'halloween', 'hanged', 'hanging', 'hangs', 'hap', 'happened', 'happening', 'happens', 'hard', 'harder', 'has', 'hashtags', 'hasn', 'hate', 'hav', 'have', 'haven', \"haven't\", 'having', 'hay', 'haywire', 'hd', 'he', 'headpho', 'headphone', 'hear', 'heard', 'hell', 'hello', 'help', 'here', 'hey', 'hi', 'high', 'his', 'hit', 'ho', 'home', 'horrendous', 'hours', 'how', 'hrs', 'hs', 'ht', 'htt', 'huge', 'human', 'hurry', 'husband', 'i', \"i'm\", 'i8', 'iCl', 'iCloud', 'iM', 'iMe', 'iMes', 'iMessage', 'iMessages', 'iMovie', 'iO', 'iOS', 'iOS11', 'iOs', 'iPad', 'iPho', 'iPhon', 'iPhone', \"iPhone's\", 'iPhone6', 'iPhone6s', 'iPhone7', 'iPhones', 'iTu', 'iTune', 'iTunes', 'icloud', 'icon', 'icons', 'id', 'idea', 'idk', 'if', 'iiiiiiii', 'ik', 'immedia', 'important', 'impossible', 'improve', 'in', 'including', 'inst', 'installed', 'insupportable', 'int', 'internet', 'into', 'ios', 'ios11', 'ios1103', 'ip', 'iphn6', 'iphon', 'iphone', 'iphoneissues', 'iphones', 'ire', 'is', 'isn', \"isn't\", 'iss', 'issue', 'issues', 'it', \"it's\", 'its', 'itsel', 'itself', 'j', 'jank', 'joined', 'ju', 'jus', 'just', 'k', 'kan', 'ke', 'keep', 'keeps', 'keyboard', 'killing', 'kind', 'kindly', 'king', 'know', 'l', 'la', 'lag', 'lagging', 'laggy', 'landscape', 'laptop', 'last', 'lat', 'late', 'lately', 'later', 'latest', 'le', 'lef', 'let', 'letter', 'letting', 'li', 'lif', 'life', 'lik', 'like', 'lil', 'lines', 'link', 'list', 'listed', 'listening', 'literally', 'little', 'live', 'lives', 'll', 'lmao', 'lo', 'lock', 'locked', 'lockin', 'locking', 'log', 'lol', 'long', 'longer', 'look', 'looking', 'looks', 'loosing', 'lose', 'lot', 'love', 'lt', 'lucky', 'm', 'mac', 'macOS', 'macos', 'made', 'magsafe', 'mail', 'maior', 'mak', 'make', 'makes', 'making', 'mal', 'malfunctioning', 'man', 'managed', 'manera', 'many', 'mark', 'mate', 'mates', 'matter', 'me', 'mean', 'meant', 'medi', 'media', 'melhorou', 'merge', 'mesmo', 'mess', 'message', 'messages', 'messed', 'meu', 'mi', 'mic', 'microfoonin', 'midnight', 'min', 'mind', 'mine', 'miss', 'mistake', 'mobile', 'mode', 'modify', 'mon', 'month', 'months', 'mor', 'more', 'morning', 'most', 'movie', 'movies', 'much', 'multi', 'multitask', 'music', 'musical', 'musun', 'mute', 'muting', 'muy', 'my', 'n', 'nFake', 'nHi', 'nI', 'nIt', 'nMy', 'nPLEASE', 'nPlz', 'nSai', 'nSuggested', 'nThis', 'nUpdated', 'nWhat', 'ne', 'necesito', 'need', 'needs', 'never', 'new', 'newer', 'newest', 'news', 'next', 'nice', 'niet', 'night', 'nightmare', 'no', 'nor', 'normal', 'not', 'nothing', 'noti', 'noticed', 'notification', 'novo', 'now', 'nuevos', 'nw', 'nwhy', 'o', 'of', 'off', 'offic', 'often', 'oh', 'ok', 'old', 'olur', 'on', 'one', 'ones', 'online', 'only', 'open', 'opened', 'operating', 'opt', 'option', 'or', 'order', 'os4', 'ou', 'our', 'out', 'ov', 'over', 'p', 'pair', 'party', 'passco', 'pay', 'payme', 'peasan', 'people', 'permanently', 'pero', 'persists', 'person', 'ph', 'phishing', 'pho', 'phon', 'phone', 'photo', 'photos', 'plans', 'please', 'pls', 'plugged', 'plus', 'podca', 'podcast', 'podcasts', 'point', 'pointless', 'popped', 'popping', 'pops', 'portion', 'possibility', 'possible', 'pounds', 'power', 'pr', 'pre', 'prete', 'pretty', 'prevent', 'previous', 'probl', 'problem', 'problema', 'problems', 'process', 'prog', 'prompt', 'prompted', 'puede', 'purc', 'purchased', 'purchases', 'put', 'qu', 'quest', 'questi', 'question', 'questions', 'qui', 'quick', 'quicker', 'quickly', 'r', 'randomly', 'rather', 're', 'read', 'reading', 'really', 'rear', 'reason', 'rec', 'receive', 'received', 'receiving', 'recent', 'recently', 'recogni', 'record', 'redemarre', 'reduced', 'reduci', 'reducing', 'redémarre', 'refunded', 'refuses', 'regarding', 'regresar', 'regret', 'reinstalled', 'relay', 'releases', 'reliable', 'removed', 'rendered', 'renewing', 'replaced', 'replacement', 'reply', 'res', 'reset', 'resetting', 'resolve', 'response', 'restar', 'restart', 'restarting', 'result', 'returning', 'rid', 'right', 'ringer', 'ringing', 'rock', 'roll', 'rude', 'ruining', 'running', 's', 'sa', 'safe', 'said', 'sake', 'same', 'savaging', 'say', 'saying', 'says', 'scan', 'scarred', 'schlägt', 'scr', 'scree', 'screen', 'screening', 'screenshot', 'se', 'sea', 'searching', 'second', 'security', 'see', 'seei', 'seeing', 'seem', 'seemed', 'seen', 'self', 'send', 'sending', 'sent', 'sentiu', 'ser', 'series', 'serv', 'setting', 'settings', 'sh', 'shame', 'shaped', 'shards', 'share', 'sharing', 'shi', 'shit', 'shite', 'sho', 'short', 'should', 'show', 'showing', 'shows', 'shut', 'si', 'sideways', 'siglo', 'signed', 'sim', 'simi', 'simil', 'since', 'site', 'skip', 'sl', 'sleep', 'slow', 'slowdown', 'slowing', 'smh', 'snapchat', 'so', 'sobrecalienta', 'social', 'software', 'solid', 'solve', 'solves', 'some', 'somebody', 'someone', 'something', 'sometimes', 'songs', 'soooo', 'sooooooo', 'sorcery', 'sorry', 'sort', 'sorted', 'sound', 'sounds', 'space', 'spam', 'speak', 'speaker', 'spend', 'spotify', 'spotted', 'spun', 'square', 'st', 'stabbed', 'started', 'starting', 'stay', 'steps', 'still', 'stop', 'stopped', 'storage', 'store', 'stored', 'straight', 'stream', 'stuck', 'su', 'suc', 'suck', 'sucks', 'sudden', 'suggestions', 'summer', 'super', 'support', 'suppose', 'sure', 'suspect', 'suspected', 'sweet', 'switch', 'sy', 'symbol', 'sys', 'system', 'só', 't', 'take', 'taking', 'tal', 'talk', 'tap', 'tarea', 'tauntingly', 'tbm', 'te', 'team', 'technology', 'tel', 'telefone', 'tell', 'telli', 'temp', 'terrible', 'tested', 'text', 'textbook', 'th', 'tha', 'thank', 'thanks', 'that', \"that's\", 'the', 'their', 'them', 'then', 'there', \"there's\", 'these', \"they're\", 'thi', 'thing', 'things', 'think', 'this', 'those', 'thought', 'thoughts', 'thousand', 'thousands', 'throu', 'thumb', 'thumbnail', 'ti', 'tim', 'time', 'timemachine', 'times', 'tips', 'tire', 'tired', 'to', 'today', 'told', 'too', 'took', 'top', 'tou', 'touch', 'trava', 'tri', 'tried', 'trip', 'true', 'try', 'trying', 'turi', 'turn', 'turned', 'turning', 'tus', 'tv4', 'tweets', 'twice', 'twist', 'twitt', 'twitter', 'two', 'tx', 'ty', 'typ', 'type', 'typing', 'u', 'uBl', 'ultima', 'um', 'umm', 'un', 'under', 'understand', 'undo', 'uninstall', 'unlock', 'unrespo', 'unstable', 'unsubscribe', 'until', 'unus', 'up', 'upda', 'updat', 'update', 'updated', 'updates', 'updating', 'upg', 'upgrade', 'upgraded', 'upgrading', 'uppercase', 'upset', 'ur', 'urgent', 'urgente', 'url', 'us', 'use', 'used', 'user', 'usin', 'using', 'usually', 'va', 'vais', 've', 'verb', 'verifying', 'version', 'very', 'via', 'vibration', 'vid', 'video', 'videos', 'virginmedia', 'virus', 'voice', 'volume', 'voor', 'vídeos', 'w', 'wa', 'wait', 'waiting', 'wake', 'want', 'wanted', 'wants', 'warrantee', 'was', 'watch', 'watchOs4', 'watched', 'way', 'we', 'website', 'week', 'weird', 'went', 'werden', 'wh', 'what', \"what's\", 'whatsapp', 'when', 'whenever', 'where', 'which', 'while', 'white', 'who', 'whole', 'whose', 'why', 'wi', 'wieder', 'wife', 'wifi', 'wil', 'will', 'wiped', 'wired', 'wit', 'with', 'withou', 'without', 'wo', 'won', \"won't\", 'wondering', 'wor', 'word', 'words', 'work', 'worked', 'worki', 'workin', 'working', 'works', 'worm', 'worse', 'worst', 'wort', 'would', 'wrong', 'wtf', 'x', 'xcode', 'y', 'ya', 'yardımcı', 'yea', 'years', 'yes', 'yesterday', 'yet', 'yo', 'you', \"you've\", 'your', 'z', '~', '´', 'Écran', 'à', 'ı', 'все', 'д', 'нормально', '–', '—', '‘', '’', '“', '”', '•', '…', '⌚', '、', '。', 'このバグ直してーーー', 'は', 'ゲームも出来なくなったしアップデートしなきゃ良かった', 'コレは本当に困る', 'デバイス', '\\uf8ff', '️', '🏻', '🏼', '🏽', '👉', '👌', '👍', '📱', '😉', '😊', '😐', '😒', '😴', '😸', '🙃', '🙋', '🙏', '🤕', '🤗', '🤘', '🤨']\nTARGET TOKENS\n['!', '\"', '%', '&', \"'Turn\", '(', ')', ',', '-', '.', '/', '1', '10', '100', '11', '13', '2', '20', '24', '25', '3', '4', '5', '5am', '6', '6s', '7', '70', '8', '8pm', '9', ':', ';', '<END>', '<START>', '?', 'AIrPods', 'About', 'Achievements', 'Activity', 'Advisor', 'Advisors', 'After', 'Air', 'AirPods', 'Alarms', 'Allow', 'Along', 'Alright', 'Also', 'And', 'Animal', 'Any', 'App', 'Apple', 'AppleCare', 'AppleTV', 'Apps', 'Are', 'As', 'AssistiveTouch', 'Assitive', 'Auto', 'Automatic', 'Availability', 'Awards', 'Awesome', 'Battery', 'Be', 'Besides', 'Bluetooth', 'But', 'Buttons', 'Can', 'Cancel', 'CarPlay', 'Center', 'Certainly', 'Change', 'Check', 'Click', 'Congratulations', 'Connect', 'Contact', 'Control', 'Could', 'Crossing', 'Currently', 'Cut', 'DM', 'DMs', 'Depending', 'Developer', 'Dictionary', 'Did', 'Direct', 'Disturb', 'Do', 'Does', \"Don't\", \"Downloads'\", 'Drafts', 'Education', 'Emoji', 'English', 'Enjoy', 'Enterprise', 'Excellent', 'Extensions', 'Face', 'Facebook', 'Family', 'Feedback', 'Feel', 'Fi', 'Fill', 'Final', 'Find', 'Finder', 'First', 'Follow', 'For', 'Force', 'Forgot', 'From', 'GBs', 'GarageBand', 'General', 'Get', 'Getting', 'Give', 'Glad', 'Go', 'Going', 'Good', 'Got', 'Great', 'HDR', 'HDR10', 'Happy', 'Has', 'Have', 'Having', 'Hello', 'Here', \"Here's\", 'Hey', 'Hi', 'Home', 'How', 'However', 'I', 'ID', 'If', 'In', 'Indeed', 'Info', 'Install', 'Interesting', 'Internet', 'Is', 'It', \"It's\", 'Join', 'Just', 'Keep', 'Keeping', 'Keyboard', 'Keyboards', 'Learn', 'Let', \"Let's\", 'Lets', 'Library', 'List', 'Lock', 'Look', 'Low', 'MMS', 'Mac', 'MacBook', 'Machine', 'Mail', 'May', 'Meet', 'Mesage', 'Message', 'Messages', 'Mode', 'Music', 'Next', 'No', 'Not', 'Notes', 'Notifications', 'November', 'OK', 'OS', 'October', 'Okay', 'Online', 'Or', 'Order', 'Our', 'Pacific', 'Pages', 'Pay', 'Perfect', 'Phone', 'Photo', 'Photos', 'Please', 'Plus', 'Podcast', 'Podcasts', 'Power', 'Preferences', 'Provide', 'Question', 'Reach', 'Reading', 'Rebooting', 'Reply', 'Reset', 'Rest', 'Restart', 'Restoring', 'Restrictions', 'SIM', 'SMS', 'SOS', 'Safari', 'Sai', 'Sales', 'See', 'Select', 'Send', 'Set', 'Settings', 'Sharing', 'Since', 'Siri', 'Snapchat', 'So', 'Software', 'Some', 'Sounds', 'Spanish', 'Spotify', 'Start', 'Steps', 'Store', 'Support', 'Sure', 'System', 'TV', 'Take', 'Tell', 'Thank', 'Thanks', 'That', \"That's\", 'The', 'Then', 'There', \"There's\", 'They', 'This', 'Time', 'To', 'Touch', 'TouchID', 'Try', 'Twitter', 'Understood', 'Update', 'Use', 'Version', 'Visit', 'Voicemail', 'Was', 'Watch', 'We', \"We'd\", \"We'll\", \"We're\", \"We've\", 'Were', 'What', \"What's\", 'WhatsApp', 'When', 'Where', 'Which', 'While', 'Wi', 'Windows', 'With', 'Would', 'X', 'You', \"You'd\", \"You'll\", \"You're\", \"You've\", 'Your', 'Zumba', 'a', 'able', 'about', 'absolute', 'access', 'accidentally', 'account', 'accounts', 'accurate', 'accurately', 'achievement', 'across', 'activate', 'activating', 'activation', 'activity', 'added', 'additional', 'address', 'adds', 'advise', 'affected', 'after', 'afterwards', 'again', 'ago', 'ahead', 'alarm', 'alarms', 'alias', 'all', 'along', 'already', 'also', 'always', 'amp', 'an', 'and', 'another', 'answer', 'answers', 'anxious', 'any', 'anything', 'anytime', 'apologize', 'app', 'appear', 'appearance', 'appears', 'applications', 'appreciate', 'apps', 'are', \"aren't\", 'around', 'article', 'as', 'ask', 'asking', 'assist', 'assistance', 'assume', 'assured', 'at', 'attempt', 'attempted', 'attempting', 'attention', 'audio', 'auto', 'autocorrect', 'available', 'avoid', 'award', 'back', 'backing', 'backup', 'backups', 'bank', 'battery', 'be', 'become', 'been', 'before', 'began', 'begin', 'behavior', 'being', 'below', 'besides', 'best', 'beta', 'better', 'billing', 'bit', 'black', 'blank', 'boot', 'both', 'bottom', 'brightness', 'bring', 'bringing', 'browser', 'bug', 'burning', 'business', 'but', 'button', 'by', 'cable', 'cables', 'calculations', 'calendar', 'calling', 'calls', 'calorie', 'came', 'camera', 'can', 'canceled', 'cannot', 'care', 'carrier', 'cause', 'causing', 'ceases', 'cellular', 'certain', 'certainly', 'challenge', 'challenges', 'chance', 'change', 'changed', 'changes', 'changing', 'charge', 'charger', 'charges', 'charging', 'chat', 'chatting', 'check', 'checked', 'checking', 'choose', 'clarify', 'clarifying', 'cleaning', 'clear', 'clearing', 'click', 'closer', 'closing', 'codes', 'come', 'comes', 'coming', 'communicate', 'compared', 'compatibilty', 'compatible', 'complaint', 'complete', 'completed', 'completely', 'completing', 'computer', 'concern', 'concerned', 'concerns', 'confirm', 'confirmation', 'confirming', 'connect', 'connected', 'connecting', 'connection', 'contact', 'contacting', 'contacts', 'containing', 'content', 'continue', 'continues', 'contiue', 'control', 'conversation', 'cord', 'correct', 'corrections', 'correctly', 'could', 'country', 'couple', 'covered', 'crashed', 'create', 'created', 'creating', 'current', 'currently', 'customize', 'd', 'data', 'date', 'day', 'days', 'deeper', 'definitely', 'delete', 'deleting', 'department', 'depending', 'depleted', 'depth', 'describing', 'description', 'detail', 'details', 'determine', 'developer', 'device', 'devices', 'dialing', 'dictionary', 'did', 'different', 'dig', 'direct', 'direction', 'directly', 'disable', 'disabled', 'disabling', 'disconnect', 'discuss', 'display', 'do', 'does', \"doesn't\", 'doing', 'don', \"don't\", 'done', 'double', 'down', 'download', 'downloaded', 'downloading', 'downloads', 'drive', 'during', 'eager', 'earlier', 'earn', 'either', 'elapsed', 'else', 'email', 'emails', 'emojis', 'enabled', 'encounter', 'encourage', 'end', 'enjoy', 'enjoying', 'ensure', 'enter', 'episodes', 'equipped', 'error', 'errors', 'especially', 'essential', 'even', 'every', 'everything', 'exact', 'exactly', 'example', 'excited', 'exclamation', 'expect', 'expected', 'experience', 'experiencing', 'experts', 'explains', 'explore', 'extended', 'extensions', 'eye', 'facing', 'far', 'feature', 'features', 'feedback', 'feel', 'feeling', 'few', 'figure', 'find', 'fine', 'firmware', 'first', 'fix', 'fixed', 'fixes', 'flash', 'folders', 'follow', 'following', 'for', 'force', 'forgot', 'forward', 'found', 'free', 'freezing', 'from', 'front', 'fully', 'functions', 'further', 'future', 'game', 'gather', 'get', 'gets', 'getting', 'give', 'giving', 'glad', 'glitching', 'globe', 'go', 'goes', 'going', 'gone', 'good', 'got', 'gotten', 'grabbing', 'grayed', 'great', 'greater', 'greyed', 'group', 'gt', 'guidance', 'guide', 'gym', 'had', 'hand', 'handle', 'hands', 'happen', 'happened', 'happening', 'happens', 'happy', 'hapy', 'has', \"hasn't\", 'have', 'having', 'he', 'hear', 'hearing', 'heat', 'help', 'helpful', 'helps', 'here', \"here's\", 'hesitate', 'higher', 'his', 'history', 'hope', 'hours', 'how', 'iCloud', 'iMac', 'iMessage', 'iMovie', 'iOS', 'iPad', 'iPhone', 'iPhones', 'iPod', 'iTunes', 'icon', 'ideas', 'identify', 'if', 'important', 'improve', 'improvements', 'in', 'include', 'including', 'incoming', 'info', 'information', 'informing', 'insert', 'install', 'installed', 'instead', 'intention', 'internet', 'into', 'investigate', 'is', 'isn', \"isn't\", 'isolate', 'isolated', 'isolation', 'issue', 'issues', 'it', \"it's\", 'items', 'its', 'itself', 'job', 'join', 'joining', 'just', 'keep', 'keeping', 'keyboard', 'keyboards', 'kind', 'know', 'lag', 'language', 'last', 'lasting', 'later', 'latest', 'learn', 'leave', 'left', 'legitimate', 'let', \"let's\", 'lets', 'letting', 'life', 'like', 'link', 'listed', 'little', 'live', 'll', 'loads', 'local', 'locate', 'located', 'locating', 'location', 'locations', 'lock', 'locked', 'log', 'logo', 'long', 'look', 'looks', 'loop', 'loss', 'lots', 'love', 'low', 'lower', 'macOS', 'made', 'maintain', 'make', 'making', 'manual', 'manually', 'many', 'mark', 'match', 'maximizing', 'may', 'mean', 'meet', 'member', 'memories', 'mentioned', 'menu', 'message', 'messages', 'messaging', 'mind', 'minutes', 'missing', 'mobile', 'mode', 'model', 'models', 'moment', 'moments', 'more', 'morning', 'most', 'move', 'movie', 'movies', 'moving', 'much', 'music', 'must', 'mute', 'muted', 'narrow', 'navigate', 'near', 'need', 'needing', 'network', 'networks', 'never', 'new', 'newer', 'newest', 'newly', 'news', 'next', 'night', 'no', 'non', 'nor', 'normal', 'not', 'notice', 'noticed', 'noticing', 'notification', 'notifications', 'now', 'number', 'obstacles', 'occur', 'occurred', 'occurring', 'occurs', 'of', 'off', 'offer', 'offline', 'often', 'ok', 'older', 'on', 'once', 'one', 'only', 'open', 'opening', 'operating', 'option', 'options', 'or', 'order', 'originate', 'other', 'our', 'out', 'outdated', 'over', 'overcome', 'own', 'page', 'pair', 'paired', 'pairing', 'part', 'particular', 'partner', 'passcode', 'password', 'path', 'pause', 'perform', 'performance', 'performing', 'persists', 'phishing', 'phone', 'photo', 'photos', 'pick', 'place', 'play', 'playback', 'played', 'playlist', 'please', 'pleasure', 'plugged', 'plus', 'point', 'pointed', 'pop', 'port', 'possible', 'posted', 'power', 'pre', 'precious', 'predictions', 'preferred', 'previous', 'previously', 'prior', 'priority', 'problem', 'problems', 'proceed', 'process', \"product's\", 'prompt', 'prompted', 'prompts', 'properly', 'provide', 'provides', 'providing', 'publicly', 'purchase', 'purchased', 'purposes', 'push', 'question', 'questions', 'quite', 'quitting', 'randomly', 're', 'reach', 'reached', 'reaching', 'read', 'ready', 'really', 'reappears', 'rear', 'recall', 'receive', 'received', 'receiving', 'recent', 'recently', 'recommend', 'record', 'recording', 'recover', 'refer', 'referring', 'refers', 'reflect', 'regain', 'region', 'reinstall', 'released', 'reliable', 'reliably', 'rely', 'reminders', 'remove', 'repairing', 'repeat', 'reply', 'report', 'request', 'required', 'reset', 'resetting', 'resolution', 'resolve', 'resolved', 'resolving', 'resource', 'resources', 'respond', 'responded', 'responding', 'response', 'rest', 'restart', 'restarted', 'restarting', 'restarts', 'restating', 'restore', 'restored', 'restoring', 'result', 'results', 'return', 'revert', 'review', 'right', 'ringer', 'room', 'root', 'rule', 'run', 'running', 's', 'safe', 'same', 'save', 'say', 'says', 'screen', 'screenshot', 'screenshots', 'section', 'secure', 'security', 'see', 'seeing', 'seem', 'seems', 'seen', 'select', 'send', 'sending', 'sent', 'separate', 'service', 'serviced', 'set', 'settings', 'setup', 'share', 'sharing', 'shoot', 'shortly', 'shot', 'should', \"shouldn't\", 'show', 'showed', 'showing', 'shown', 'shows', 'side', 'sign', 'signed', 'similar', 'since', 'situation', 'slowly', 'slowness', 'smooth', 'smoothly', 'snapshots', 'so', 'software', 'solution', 'solve', 'some', 'sometimes', 'song', 'songs', 'soon', 'sorry', 'sort', 'sorted', 'sound', 'sounds', 'space', 'speaker', 'speaking', 'special', 'specific', 'specifics', 'speculate', 'standard', 'start', 'started', 'starting', 'station', 'stations', 'status', 'step', 'steps', 'still', 'storage', 'store', 'straightened', 'stream', 'stuck', 'submit', 'successfully', 'suggest', 'suggestion', 'suggestions', 'suited', 'support', 'supported', 'supports', 'sure', 'surely', 'surfing', 'suspicious', 'swipe', 'switch', 'symbol', 'sync', 'system', 't', 'tab', 'take', 'taken', 'taking', 'talk', 'tap', 'tapping', 'tasks', 'team', 'tell', 'telling', 'temporarily', 'test', 'testing', 'text', 'texts', 'than', 'thank', 'thanks', 'that', \"that'll\", \"that's\", 'the', 'their', 'them', 'then', 'there', \"there's\", 'these', 'they', 'thing', 'things', 'this', 'those', 'though', 'thoughts', 'through', 'time', 'tips', 'to', 'today', 'together', 'toggle', 'too', 'top', 'totally', 'touch', 'tough', 'towards', 'track', 'trash', 'travel', 'trick', 'tried', 'tries', 'trip', 'trouble', 'troubles', 'troubleshoot', 'troubleshooting', 'try', 'trying', 'turn', 'turned', 'turning', 'turns', 'type', 'types', 'typically', 'unable', 'under', 'understand', 'understanding', 'unlocked', 'unpairing', 'unrecognized', 'unresponsive', 'until', 'unwanted', 'up', 'update', 'updated', 'updates', 'updating', 'us', 'use', 'used', 'user', 'users', 'using', 'value', 'varies', 've', 'verify', 'verifying', 'version', 'very', 'via', 'video', 'videos', 'view', 'visit', 'volume', 'wait', 'wake', 'want', 'wanting', 'was', 'watch', 'watchOS', 'watching', 'way', 'ways', 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'web', 'website', 'websites', 'weekend', 'welcome', 'well', 'went', 'were', 'what', \"what's\", 'when', 'where', 'which', 'while', 'why', 'will', 'windows', 'wireless', 'with', 'within', 'without', \"won't\", 'work', 'worked', 'working', 'workout', 'works', 'worries', 'worry', 'worrying', 'would', \"wouldn't\", 'yesterday', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', '’', '\\uf8ff']\nINPUT FEATURES\n{'!': 0, '\"': 1, '#': 2, '$': 3, '%': 4, '&': 5, '(': 6, ')': 7, '*': 8, '+': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '000': 15, '03': 16, '1': 17, '10': 18, '100': 19, '100335493202': 20, '11': 21, \"11'\": 22, '12': 23, '13': 24, '14': 25, '15': 26, '15B150': 27, '18': 28, '1h': 29, '1にあげたらTwitter少し見てるだけだし低電力モードなのに20パーへったぞ': 30, '2': 31, '20': 32, '2010': 33, '2011': 34, '23': 35, '256': 36, '28': 37, '2nd': 38, '3': 39, '30': 40, '38': 41, '3D': 42, '3rd': 43, '4': 44, '42': 45, '4times': 46, '5': 47, '5S': 48, '5s': 49, '6': 50, '60': 51, '6S': 52, '6SPlus': 53, '6s': 54, '6sPlus': 55, '7': 56, '7plus': 57, '8': 58, '9TB': 59, ':': 60, ';': 61, '=': 62, '?': 63, 'A': 64, 'ACONTECENDO': 65, 'AF': 66, 'AFTER': 67, 'AGAIN': 68, 'AND': 69, 'APPLE': 70, 'AQUI': 71, 'ASA': 72, 'AT': 73, 'Actualize': 74, 'Add': 75, 'After': 76, 'AirPods': 77, 'Akku': 78, 'Aktivierung': 79, 'Alguém': 80, 'All': 81, 'Already': 82, 'Also': 83, 'Although': 84, 'Amma': 85, 'And': 86, 'Animal': 87, 'Annnnnnd': 88, 'Another': 89, 'Any': 90, 'Anyone': 91, 'App': 92, 'Apple': 93, 'AppleCa': 94, 'AppleWatch': 95, 'Applewatch': 96, 'At': 97, 'Auto': 98, 'Ayo': 99, 'Ayúdame': 100, 'BLUETOOTH': 101, 'BRAND': 102, 'BRO': 103, 'BUTTON': 104, 'Baje': 105, 'Basically': 106, 'Battery': 107, 'Bec': 108, 'Been': 109, 'Benutzung': 110, 'Bienvenida': 111, 'Bl': 112, 'Bluetoo': 113, 'Bluetooth': 114, 'Both': 115, 'Bridgeport': 116, 'Bro': 117, 'But': 118, 'C': 119, 'CONSTANTLY': 120, 'Ca': 121, 'Calendar': 122, 'Can': 123, 'Cannot': 124, 'Care': 125, 'Case': 126, 'Chall': 127, 'Challenge': 128, 'Chang': 129, 'Chat': 130, 'Checked': 131, 'Cmo': 132, 'Come': 133, 'Congrats': 134, 'Connect': 135, 'Contacts': 136, 'Cr': 137, 'Cupertino': 138, 'DL': 139, 'DM': 140, 'DMs': 141, 'DOES': 142, 'DOESN': 143, 'Damn': 144, 'Day': 145, 'De': 146, 'Dear': 147, 'Deleted': 148, 'Depende': 149, 'Depois': 150, 'Did': 151, \"Didn't\": 152, 'Disappointed': 153, 'Do': 154, 'Does': 155, 'DolbyVision': 156, 'Don': 157, 'Downloaded': 158, 'EVER': 159, 'EVERYTIME': 160, 'Either': 161, 'El': 162, 'Em': 163, 'English': 164, 'Eu': 165, 'Even': 166, 'Ever': 167, 'Every': 168, 'Everytime': 169, 'Excuse': 170, 'Eye': 171, 'FI': 172, 'FIX': 173, 'FOCO': 174, 'FUCK': 175, 'FYI': 176, 'Fail': 177, 'Ffs': 178, 'Fi': 179, 'Fishing': 180, 'Fix': 181, 'Fixed': 182, 'Folders': 183, 'Followed': 184, 'For': 185, 'Freezing': 186, 'Friday': 187, 'GA': 188, 'GOT': 189, 'Germ': 190, 'Get': 191, 'Gmail': 192, 'Go': 193, 'God': 194, 'Got': 195, 'Great': 196, 'H': 197, 'HAPP': 198, 'HELP': 199, 'HEY': 200, 'HOME': 201, 'Has': 202, 'Have': 203, 'Hello': 204, 'Help': 205, 'Here': 206, 'Hey': 207, 'Heyyy': 208, 'Hi': 209, 'High': 210, 'HighSierra': 211, 'Hmm': 212, 'Hoe': 213, 'Hola': 214, 'How': 215, 'I': 216, \"I'm\": 217, \"I've\": 218, 'ID': 219, 'IOS': 220, 'IOS11': 221, 'IOSissues': 222, 'IPhone': 223, 'IS': 224, 'IT': 225, 'If': 226, 'Ill': 227, 'Im': 228, 'Impossible': 229, 'Installed': 230, 'Ios': 231, 'Ipad': 232, 'Iphone': 233, 'IphoneX': 234, 'Is': 235, 'It': 236, \"It's\": 237, 'Its': 238, 'Jk': 239, 'Just': 240, 'KEEP': 241, 'Keep': 242, 'Keeps': 243, 'Keyboard': 244, 'Klucííí': 245, 'LTE': 246, 'Lacie': 247, 'Landscape': 248, 'Last': 249, 'Latest': 250, 'LiFE': 251, 'Like': 252, 'Listen': 253, 'Lo': 254, 'Location': 255, 'Lockout': 256, 'Lol': 257, 'Love': 258, 'MAC': 259, 'ME': 260, 'MMS': 261, 'MY': 262, 'Mac': 263, 'MacBoo': 264, 'MacBook': 265, 'MacOS': 266, 'MacPro': 267, 'Man': 268, 'Maybe': 269, 'Min': 270, 'Mine': 271, 'Mmmmm': 272, 'Mobile': 273, 'More': 274, 'Multitasking': 275, 'Musi': 276, 'Music': 277, 'My': 278, 'NEVER': 279, 'NEW': 280, 'NOW': 281, 'Nachrichten': 282, 'No': 283, 'Nope': 284, 'Not': 285, 'Noted': 286, 'Nothing': 287, 'Novem': 288, 'November': 289, 'Now': 290, 'Não': 291, 'O': 292, 'OK': 293, 'ONLY': 294, 'OTG': 295, 'Oct': 296, 'October': 297, 'Oh': 298, 'Ohh': 299, 'Ok': 300, 'Okay': 301, 'Okey': 302, 'Omg': 303, 'On': 304, 'Only': 305, 'Open': 306, 'Other': 307, 'Overlapping': 308, 'Oye': 309, 'PHONE': 310, 'PIOROU': 311, 'PR': 312, 'PT1': 313, 'Pa': 314, 'Paris': 315, 'Ph': 316, 'Phone': 317, 'Pl': 318, 'Pla': 319, 'Please': 320, 'Plus': 321, 'Press': 322, 'Pro': 323, 'Problem': 324, 'Progress': 325, 'Q': 326, 'Question': 327, 'RT': 328, 'Really': 329, 'Restarting': 330, 'SAME': 331, 'SE': 332, 'SMS': 333, 'SY': 334, 'Saf': 335, 'Safari': 336, 'Same': 337, 'Saurabh': 338, 'Scar': 339, 'See': 340, 'Seems': 341, 'Sent': 342, 'Series': 343, 'Series1': 344, 'Seriously': 345, 'Should': 346, 'Sierra': 347, 'Since': 348, 'Singapore': 349, 'Siri': 350, 'So': 351, 'Sometimes': 352, 'Sooooooo': 353, 'Sorry': 354, 'Sta': 355, 'Standby': 356, 'Steve': 357, 'Still': 358, 'Stop': 359, 'Store': 360, 'Support': 361, 'T': 362, 'THE': 363, 'THIS': 364, 'TIME': 365, 'TO': 366, 'TURN': 367, 'TV': 368, 'TYPE': 369, 'Teally': 370, 'Tengo': 371, 'Terror': 372, 'Tf': 373, 'Thank': 374, 'Thanks': 375, 'That': 376, 'The': 377, 'These': 378, 'This': 379, 'TimeMachine': 380, 'Tip': 381, 'To': 382, 'Today': 383, 'Todos': 384, 'Too': 385, 'Top': 386, 'Touch': 387, 'Tried': 388, 'Truly': 389, 'Trying': 390, 'Tudo': 391, 'Twitter': 392, 'Type': 393, 'TÁ': 394, 'Ummm': 395, 'Unable': 396, 'Update': 397, 'Updated': 398, 'Upgrade': 399, 'Upgraded': 400, 'Ur': 401, 'Using': 402, 'Version': 403, 'Very': 404, 'Videoshop': 405, 'W': 406, 'WHY': 407, 'WORK': 408, 'WTF': 409, 'Wait': 410, 'Wasn': 411, 'Watch': 412, 'WatchOS': 413, 'We': 414, 'Well': 415, 'What': 416, 'Whats': 417, 'When': 418, 'Where': 419, 'Why': 420, 'WiFi': 421, 'Will': 422, 'Won': 423, 'Worked': 424, 'Wow': 425, 'Wro': 426, 'Wtf': 427, 'X': 428, 'XXI': 429, 'Y': 430, 'Yay': 431, 'Yayz': 432, 'Yes': 433, 'Yo': 434, 'You': 435, 'Youtube': 436, 'Zumba': 437, '[': 438, '\\\\': 439, ']': 440, '^': 441, '__email__': 442, '`': 443, 'a': 444, 'able': 445, 'abo': 446, 'about': 447, 'absolutely': 448, 'ac': 449, 'acc': 450, 'access': 451, 'acciden': 452, 'account': 453, 'acting': 454, 'activity': 455, 'actua': 456, 'actual': 457, 'actualiz': 458, 'adapter': 459, 'add': 460, 'added': 461, 'adding': 462, 'address': 463, 'adjust': 464, 'admin': 465, 'adress': 466, 'aft': 467, 'after': 468, 'ago': 469, 'ai': 470, 'al': 471, 'alarm': 472, 'all': 473, 'already': 474, 'also': 475, 'am': 476, 'amazing': 477, 'amount': 478, 'amp': 479, 'an': 480, 'and': 481, 'anno': 482, 'annoying': 483, 'another': 484, 'answers': 485, 'any': 486, 'anymor': 487, 'anymore': 488, 'anyone': 489, 'ap': 490, 'app': 491, 'apple': 492, 'applem': 493, 'approved': 494, 'apps': 495, 'appstore': 496, 'appt': 497, 'apresenta': 498, 'ar': 499, 'are': 500, 'aren': 501, 'arreglar': 502, 'art': 503, 'as': 504, 'asking': 505, 'at': 506, 'attempts': 507, 'atualizado': 508, 'au': 509, 'audio': 510, 'auto': 511, 'autocorrect': 512, 'autocorrecting': 513, 'available': 514, 'avg': 515, 'award': 516, 'awful': 517, 'b': 518, 'ba': 519, 'back': 520, 'backed': 521, 'backup': 522, 'bana': 523, 'bar': 524, 'basically': 525, 'bat': 526, 'bateria': 527, 'batte': 528, 'batter': 529, 'battery': 530, 'bc': 531, 'be': 532, 'bec': 533, 'became': 534, 'becaus': 535, 'because': 536, 'becom': 537, 'bee': 538, 'been': 539, 'bef': 540, 'before': 541, 'behaviour': 542, 'bei': 543, 'being': 544, 'belie': 545, 'believe': 546, 'best': 547, 'beta': 548, 'billion': 549, 'bitch': 550, 'blank': 551, 'blowing': 552, 'bom': 553, 'bonitos': 554, 'boot': 555, 'bose': 556, 'both': 557, 'bought': 558, 'box': 559, 'boxed': 560, 'boxes': 561, 'brain': 562, 'bro': 563, 'broadcast': 564, 'broken': 565, 'bu': 566, 'bug': 567, 'buggie': 568, 'buggy': 569, 'bugs': 570, 'bullshit': 571, 'burned': 572, 'burning': 573, 'but': 574, 'button': 575, 'buy': 576, 'by': 577, 'bypass': 578, 'c': 579, 'ca': 580, 'cale': 581, 'calendar': 582, 'call': 583, 'called': 584, 'came': 585, 'camera': 586, 'can': 587, \"can't\": 588, 'cancel': 589, 'cannot': 590, 'cant': 591, 'capital': 592, 'card': 593, 'casa': 594, 'cassé': 595, 'ce': 596, 'center': 597, 'centres': 598, 'certai': 599, 'chal': 600, 'challenge': 601, 'chan': 602, 'change': 603, 'changi': 604, 'changing': 605, 'character': 606, 'charged': 607, 'charger': 608, 'charging': 609, 'chat': 610, 'chats': 611, 'chatti': 612, 'check': 613, 'checked': 614, 'clavier': 615, 'cle': 616, 'close': 617, 'closed': 618, 'cmon': 619, 'co': 620, 'collective': 621, 'com': 622, 'combi': 623, 'come': 624, 'coming': 625, 'como': 626, 'complain': 627, 'complaining': 628, 'complet': 629, 'completed': 630, 'completely': 631, 'computer': 632, 'con': 633, 'conc': 634, 'conectar': 635, 'confirm': 636, 'conne': 637, 'connect': 638, 'connected': 639, 'connecter': 640, 'connection': 641, 'considering': 642, 'consistent': 643, 'consistently': 644, 'consumes': 645, 'consumo': 646, 'consumpt': 647, 'contact': 648, 'contacts': 649, 'contr': 650, 'control': 651, 'controls': 652, 'convinc': 653, 'cool': 654, 'cost': 655, 'couldn': 656, \"couldn't\": 657, 'couple': 658, 'coverage': 659, 'covered': 660, 'crackli': 661, 'crackling': 662, 'crash': 663, 'crashed': 664, 'crashing': 665, 'crazy': 666, 'create': 667, 'creates': 668, 'cripple': 669, 'cu': 670, 'cual': 671, 'cuando': 672, 'currently': 673, 'customer': 674, 'cuts': 675, 'cycle': 676, 'd': 677, 'da': 678, 'damaged': 679, 'damn': 680, 'data': 681, 'date': 682, 'dating': 683, 'day': 684, 'days': 685, 'de': 686, 'dear': 687, 'decided': 688, 'decides': 689, 'del': 690, 'deleted': 691, 'deleting': 692, 'delivery': 693, 'dementia': 694, 'details': 695, 'developper': 696, 'diagno': 697, 'dial': 698, 'did': 699, 'didn': 700, 'died': 701, 'dies': 702, 'different': 703, 'direct': 704, 'disable': 705, 'disappearing': 706, 'disappointed': 707, 'disfuncti': 708, 'dm': 709, 'do': 710, 'docs': 711, 'doe': 712, 'does': 713, 'doesn': 714, \"doesn't\": 715, 'doesnt': 716, 'doing': 717, 'don': 718, \"don't\": 719, 'done': 720, 'doubt': 721, 'down': 722, 'downgrade': 723, 'downl': 724, 'download': 725, 'downloaded': 726, 'downloading': 727, 'drain': 728, 'draining': 729, 'drains': 730, 'drama': 731, 'dropped': 732, 'du': 733, 'dumb': 734, 'duplicated': 735, 'dying': 736, 'děláte': 737, 'e': 738, 'each': 739, 'ear': 740, 'earbuds': 741, 'either': 742, 'el': 743, 'else': 744, 'emai': 745, 'email': 746, 'emails': 747, 'embarrassing': 748, 'emojis': 749, 'en': 750, 'enable': 751, 'entire': 752, 'epilepsy': 753, 'epıl': 754, 'equipo': 755, 'eras': 756, 'erased': 757, 'error': 758, 'es': 759, 'est': 760, 'estão': 761, 'et': 762, 'etc': 763, 'ev': 764, 'even': 765, 'ever': 766, 'every': 767, 'everytime': 768, 'evry': 769, 'example': 770, 'excuse': 771, 'expected': 772, 'experiencing': 773, 'expert': 774, 'explain': 775, 'explanatory': 776, 'external': 777, 'externe': 778, 'extr': 779, 'eye': 780, 'f': 781, 'fa': 782, 'facing': 783, 'fact': 784, 'failed': 785, 'failure': 786, 'fait': 787, 'fake': 788, 'far': 789, 'fast': 790, 'fear': 791, 'feature': 792, 'features': 793, 'fed': 794, 'feel': 795, 'feels': 796, 'fehl': 797, 'fetc': 798, 'fetched': 799, 'few': 800, 'figure': 801, 'figured': 802, 'finally': 803, 'find': 804, 'fine': 805, 'fix': 806, 'fixed': 807, 'fixing': 808, 'fo': 809, 'focu': 810, 'focusing': 811, 'folks': 812, 'followed': 813, 'following': 814, 'for': 815, 'force': 816, 'forced': 817, 'fot': 818, 'fotos': 819, 'fraud': 820, 'freaking': 821, 'free': 822, 'freeze': 823, 'freezes': 824, 'freezin': 825, 'freezing': 826, 'fri': 827, 'frnds': 828, 'from': 829, 'froze': 830, 'frustrated': 831, 'frustrating': 832, 'fuccin': 833, 'fuck': 834, 'fucking': 835, 'fucks': 836, 'full': 837, 'fully': 838, 'functi': 839, 'further': 840, 'fuxking': 841, 'g': 842, 'get': 843, 'gets': 844, 'getting': 845, 'gift': 846, 'give': 847, 'giving': 848, 'glass': 849, 'glitch': 850, 'glitching': 851, 'glitchy': 852, 'go': 853, 'god': 854, 'going': 855, 'gon': 856, 'gone': 857, 'gonna': 858, 'good': 859, 'googled': 860, 'got': 861, 'gotta': 862, 'gr': 863, 'great': 864, 'green': 865, 'grief': 866, 'group': 867, 'guess': 868, 'guy': 869, 'guys': 870, 'h': 871, 'ha': 872, 'had': 873, 'halloween': 874, 'hanged': 875, 'hanging': 876, 'hangs': 877, 'hap': 878, 'happened': 879, 'happening': 880, 'happens': 881, 'hard': 882, 'harder': 883, 'has': 884, 'hashtags': 885, 'hasn': 886, 'hate': 887, 'hav': 888, 'have': 889, 'haven': 890, \"haven't\": 891, 'having': 892, 'hay': 893, 'haywire': 894, 'hd': 895, 'he': 896, 'headpho': 897, 'headphone': 898, 'hear': 899, 'heard': 900, 'hell': 901, 'hello': 902, 'help': 903, 'here': 904, 'hey': 905, 'hi': 906, 'high': 907, 'his': 908, 'hit': 909, 'ho': 910, 'home': 911, 'horrendous': 912, 'hours': 913, 'how': 914, 'hrs': 915, 'hs': 916, 'ht': 917, 'htt': 918, 'huge': 919, 'human': 920, 'hurry': 921, 'husband': 922, 'i': 923, \"i'm\": 924, 'i8': 925, 'iCl': 926, 'iCloud': 927, 'iM': 928, 'iMe': 929, 'iMes': 930, 'iMessage': 931, 'iMessages': 932, 'iMovie': 933, 'iO': 934, 'iOS': 935, 'iOS11': 936, 'iOs': 937, 'iPad': 938, 'iPho': 939, 'iPhon': 940, 'iPhone': 941, \"iPhone's\": 942, 'iPhone6': 943, 'iPhone6s': 944, 'iPhone7': 945, 'iPhones': 946, 'iTu': 947, 'iTune': 948, 'iTunes': 949, 'icloud': 950, 'icon': 951, 'icons': 952, 'id': 953, 'idea': 954, 'idk': 955, 'if': 956, 'iiiiiiii': 957, 'ik': 958, 'immedia': 959, 'important': 960, 'impossible': 961, 'improve': 962, 'in': 963, 'including': 964, 'inst': 965, 'installed': 966, 'insupportable': 967, 'int': 968, 'internet': 969, 'into': 970, 'ios': 971, 'ios11': 972, 'ios1103': 973, 'ip': 974, 'iphn6': 975, 'iphon': 976, 'iphone': 977, 'iphoneissues': 978, 'iphones': 979, 'ire': 980, 'is': 981, 'isn': 982, \"isn't\": 983, 'iss': 984, 'issue': 985, 'issues': 986, 'it': 987, \"it's\": 988, 'its': 989, 'itsel': 990, 'itself': 991, 'j': 992, 'jank': 993, 'joined': 994, 'ju': 995, 'jus': 996, 'just': 997, 'k': 998, 'kan': 999, 'ke': 1000, 'keep': 1001, 'keeps': 1002, 'keyboard': 1003, 'killing': 1004, 'kind': 1005, 'kindly': 1006, 'king': 1007, 'know': 1008, 'l': 1009, 'la': 1010, 'lag': 1011, 'lagging': 1012, 'laggy': 1013, 'landscape': 1014, 'laptop': 1015, 'last': 1016, 'lat': 1017, 'late': 1018, 'lately': 1019, 'later': 1020, 'latest': 1021, 'le': 1022, 'lef': 1023, 'let': 1024, 'letter': 1025, 'letting': 1026, 'li': 1027, 'lif': 1028, 'life': 1029, 'lik': 1030, 'like': 1031, 'lil': 1032, 'lines': 1033, 'link': 1034, 'list': 1035, 'listed': 1036, 'listening': 1037, 'literally': 1038, 'little': 1039, 'live': 1040, 'lives': 1041, 'll': 1042, 'lmao': 1043, 'lo': 1044, 'lock': 1045, 'locked': 1046, 'lockin': 1047, 'locking': 1048, 'log': 1049, 'lol': 1050, 'long': 1051, 'longer': 1052, 'look': 1053, 'looking': 1054, 'looks': 1055, 'loosing': 1056, 'lose': 1057, 'lot': 1058, 'love': 1059, 'lt': 1060, 'lucky': 1061, 'm': 1062, 'mac': 1063, 'macOS': 1064, 'macos': 1065, 'made': 1066, 'magsafe': 1067, 'mail': 1068, 'maior': 1069, 'mak': 1070, 'make': 1071, 'makes': 1072, 'making': 1073, 'mal': 1074, 'malfunctioning': 1075, 'man': 1076, 'managed': 1077, 'manera': 1078, 'many': 1079, 'mark': 1080, 'mate': 1081, 'mates': 1082, 'matter': 1083, 'me': 1084, 'mean': 1085, 'meant': 1086, 'medi': 1087, 'media': 1088, 'melhorou': 1089, 'merge': 1090, 'mesmo': 1091, 'mess': 1092, 'message': 1093, 'messages': 1094, 'messed': 1095, 'meu': 1096, 'mi': 1097, 'mic': 1098, 'microfoonin': 1099, 'midnight': 1100, 'min': 1101, 'mind': 1102, 'mine': 1103, 'miss': 1104, 'mistake': 1105, 'mobile': 1106, 'mode': 1107, 'modify': 1108, 'mon': 1109, 'month': 1110, 'months': 1111, 'mor': 1112, 'more': 1113, 'morning': 1114, 'most': 1115, 'movie': 1116, 'movies': 1117, 'much': 1118, 'multi': 1119, 'multitask': 1120, 'music': 1121, 'musical': 1122, 'musun': 1123, 'mute': 1124, 'muting': 1125, 'muy': 1126, 'my': 1127, 'n': 1128, 'nFake': 1129, 'nHi': 1130, 'nI': 1131, 'nIt': 1132, 'nMy': 1133, 'nPLEASE': 1134, 'nPlz': 1135, 'nSai': 1136, 'nSuggested': 1137, 'nThis': 1138, 'nUpdated': 1139, 'nWhat': 1140, 'ne': 1141, 'necesito': 1142, 'need': 1143, 'needs': 1144, 'never': 1145, 'new': 1146, 'newer': 1147, 'newest': 1148, 'news': 1149, 'next': 1150, 'nice': 1151, 'niet': 1152, 'night': 1153, 'nightmare': 1154, 'no': 1155, 'nor': 1156, 'normal': 1157, 'not': 1158, 'nothing': 1159, 'noti': 1160, 'noticed': 1161, 'notification': 1162, 'novo': 1163, 'now': 1164, 'nuevos': 1165, 'nw': 1166, 'nwhy': 1167, 'o': 1168, 'of': 1169, 'off': 1170, 'offic': 1171, 'often': 1172, 'oh': 1173, 'ok': 1174, 'old': 1175, 'olur': 1176, 'on': 1177, 'one': 1178, 'ones': 1179, 'online': 1180, 'only': 1181, 'open': 1182, 'opened': 1183, 'operating': 1184, 'opt': 1185, 'option': 1186, 'or': 1187, 'order': 1188, 'os4': 1189, 'ou': 1190, 'our': 1191, 'out': 1192, 'ov': 1193, 'over': 1194, 'p': 1195, 'pair': 1196, 'party': 1197, 'passco': 1198, 'pay': 1199, 'payme': 1200, 'peasan': 1201, 'people': 1202, 'permanently': 1203, 'pero': 1204, 'persists': 1205, 'person': 1206, 'ph': 1207, 'phishing': 1208, 'pho': 1209, 'phon': 1210, 'phone': 1211, 'photo': 1212, 'photos': 1213, 'plans': 1214, 'please': 1215, 'pls': 1216, 'plugged': 1217, 'plus': 1218, 'podca': 1219, 'podcast': 1220, 'podcasts': 1221, 'point': 1222, 'pointless': 1223, 'popped': 1224, 'popping': 1225, 'pops': 1226, 'portion': 1227, 'possibility': 1228, 'possible': 1229, 'pounds': 1230, 'power': 1231, 'pr': 1232, 'pre': 1233, 'prete': 1234, 'pretty': 1235, 'prevent': 1236, 'previous': 1237, 'probl': 1238, 'problem': 1239, 'problema': 1240, 'problems': 1241, 'process': 1242, 'prog': 1243, 'prompt': 1244, 'prompted': 1245, 'puede': 1246, 'purc': 1247, 'purchased': 1248, 'purchases': 1249, 'put': 1250, 'qu': 1251, 'quest': 1252, 'questi': 1253, 'question': 1254, 'questions': 1255, 'qui': 1256, 'quick': 1257, 'quicker': 1258, 'quickly': 1259, 'r': 1260, 'randomly': 1261, 'rather': 1262, 're': 1263, 'read': 1264, 'reading': 1265, 'really': 1266, 'rear': 1267, 'reason': 1268, 'rec': 1269, 'receive': 1270, 'received': 1271, 'receiving': 1272, 'recent': 1273, 'recently': 1274, 'recogni': 1275, 'record': 1276, 'redemarre': 1277, 'reduced': 1278, 'reduci': 1279, 'reducing': 1280, 'redémarre': 1281, 'refunded': 1282, 'refuses': 1283, 'regarding': 1284, 'regresar': 1285, 'regret': 1286, 'reinstalled': 1287, 'relay': 1288, 'releases': 1289, 'reliable': 1290, 'removed': 1291, 'rendered': 1292, 'renewing': 1293, 'replaced': 1294, 'replacement': 1295, 'reply': 1296, 'res': 1297, 'reset': 1298, 'resetting': 1299, 'resolve': 1300, 'response': 1301, 'restar': 1302, 'restart': 1303, 'restarting': 1304, 'result': 1305, 'returning': 1306, 'rid': 1307, 'right': 1308, 'ringer': 1309, 'ringing': 1310, 'rock': 1311, 'roll': 1312, 'rude': 1313, 'ruining': 1314, 'running': 1315, 's': 1316, 'sa': 1317, 'safe': 1318, 'said': 1319, 'sake': 1320, 'same': 1321, 'savaging': 1322, 'say': 1323, 'saying': 1324, 'says': 1325, 'scan': 1326, 'scarred': 1327, 'schlägt': 1328, 'scr': 1329, 'scree': 1330, 'screen': 1331, 'screening': 1332, 'screenshot': 1333, 'se': 1334, 'sea': 1335, 'searching': 1336, 'second': 1337, 'security': 1338, 'see': 1339, 'seei': 1340, 'seeing': 1341, 'seem': 1342, 'seemed': 1343, 'seen': 1344, 'self': 1345, 'send': 1346, 'sending': 1347, 'sent': 1348, 'sentiu': 1349, 'ser': 1350, 'series': 1351, 'serv': 1352, 'setting': 1353, 'settings': 1354, 'sh': 1355, 'shame': 1356, 'shaped': 1357, 'shards': 1358, 'share': 1359, 'sharing': 1360, 'shi': 1361, 'shit': 1362, 'shite': 1363, 'sho': 1364, 'short': 1365, 'should': 1366, 'show': 1367, 'showing': 1368, 'shows': 1369, 'shut': 1370, 'si': 1371, 'sideways': 1372, 'siglo': 1373, 'signed': 1374, 'sim': 1375, 'simi': 1376, 'simil': 1377, 'since': 1378, 'site': 1379, 'skip': 1380, 'sl': 1381, 'sleep': 1382, 'slow': 1383, 'slowdown': 1384, 'slowing': 1385, 'smh': 1386, 'snapchat': 1387, 'so': 1388, 'sobrecalienta': 1389, 'social': 1390, 'software': 1391, 'solid': 1392, 'solve': 1393, 'solves': 1394, 'some': 1395, 'somebody': 1396, 'someone': 1397, 'something': 1398, 'sometimes': 1399, 'songs': 1400, 'soooo': 1401, 'sooooooo': 1402, 'sorcery': 1403, 'sorry': 1404, 'sort': 1405, 'sorted': 1406, 'sound': 1407, 'sounds': 1408, 'space': 1409, 'spam': 1410, 'speak': 1411, 'speaker': 1412, 'spend': 1413, 'spotify': 1414, 'spotted': 1415, 'spun': 1416, 'square': 1417, 'st': 1418, 'stabbed': 1419, 'started': 1420, 'starting': 1421, 'stay': 1422, 'steps': 1423, 'still': 1424, 'stop': 1425, 'stopped': 1426, 'storage': 1427, 'store': 1428, 'stored': 1429, 'straight': 1430, 'stream': 1431, 'stuck': 1432, 'su': 1433, 'suc': 1434, 'suck': 1435, 'sucks': 1436, 'sudden': 1437, 'suggestions': 1438, 'summer': 1439, 'super': 1440, 'support': 1441, 'suppose': 1442, 'sure': 1443, 'suspect': 1444, 'suspected': 1445, 'sweet': 1446, 'switch': 1447, 'sy': 1448, 'symbol': 1449, 'sys': 1450, 'system': 1451, 'só': 1452, 't': 1453, 'take': 1454, 'taking': 1455, 'tal': 1456, 'talk': 1457, 'tap': 1458, 'tarea': 1459, 'tauntingly': 1460, 'tbm': 1461, 'te': 1462, 'team': 1463, 'technology': 1464, 'tel': 1465, 'telefone': 1466, 'tell': 1467, 'telli': 1468, 'temp': 1469, 'terrible': 1470, 'tested': 1471, 'text': 1472, 'textbook': 1473, 'th': 1474, 'tha': 1475, 'thank': 1476, 'thanks': 1477, 'that': 1478, \"that's\": 1479, 'the': 1480, 'their': 1481, 'them': 1482, 'then': 1483, 'there': 1484, \"there's\": 1485, 'these': 1486, \"they're\": 1487, 'thi': 1488, 'thing': 1489, 'things': 1490, 'think': 1491, 'this': 1492, 'those': 1493, 'thought': 1494, 'thoughts': 1495, 'thousand': 1496, 'thousands': 1497, 'throu': 1498, 'thumb': 1499, 'thumbnail': 1500, 'ti': 1501, 'tim': 1502, 'time': 1503, 'timemachine': 1504, 'times': 1505, 'tips': 1506, 'tire': 1507, 'tired': 1508, 'to': 1509, 'today': 1510, 'told': 1511, 'too': 1512, 'took': 1513, 'top': 1514, 'tou': 1515, 'touch': 1516, 'trava': 1517, 'tri': 1518, 'tried': 1519, 'trip': 1520, 'true': 1521, 'try': 1522, 'trying': 1523, 'turi': 1524, 'turn': 1525, 'turned': 1526, 'turning': 1527, 'tus': 1528, 'tv4': 1529, 'tweets': 1530, 'twice': 1531, 'twist': 1532, 'twitt': 1533, 'twitter': 1534, 'two': 1535, 'tx': 1536, 'ty': 1537, 'typ': 1538, 'type': 1539, 'typing': 1540, 'u': 1541, 'uBl': 1542, 'ultima': 1543, 'um': 1544, 'umm': 1545, 'un': 1546, 'under': 1547, 'understand': 1548, 'undo': 1549, 'uninstall': 1550, 'unlock': 1551, 'unrespo': 1552, 'unstable': 1553, 'unsubscribe': 1554, 'until': 1555, 'unus': 1556, 'up': 1557, 'upda': 1558, 'updat': 1559, 'update': 1560, 'updated': 1561, 'updates': 1562, 'updating': 1563, 'upg': 1564, 'upgrade': 1565, 'upgraded': 1566, 'upgrading': 1567, 'uppercase': 1568, 'upset': 1569, 'ur': 1570, 'urgent': 1571, 'urgente': 1572, 'url': 1573, 'us': 1574, 'use': 1575, 'used': 1576, 'user': 1577, 'usin': 1578, 'using': 1579, 'usually': 1580, 'va': 1581, 'vais': 1582, 've': 1583, 'verb': 1584, 'verifying': 1585, 'version': 1586, 'very': 1587, 'via': 1588, 'vibration': 1589, 'vid': 1590, 'video': 1591, 'videos': 1592, 'virginmedia': 1593, 'virus': 1594, 'voice': 1595, 'volume': 1596, 'voor': 1597, 'vídeos': 1598, 'w': 1599, 'wa': 1600, 'wait': 1601, 'waiting': 1602, 'wake': 1603, 'want': 1604, 'wanted': 1605, 'wants': 1606, 'warrantee': 1607, 'was': 1608, 'watch': 1609, 'watchOs4': 1610, 'watched': 1611, 'way': 1612, 'we': 1613, 'website': 1614, 'week': 1615, 'weird': 1616, 'went': 1617, 'werden': 1618, 'wh': 1619, 'what': 1620, \"what's\": 1621, 'whatsapp': 1622, 'when': 1623, 'whenever': 1624, 'where': 1625, 'which': 1626, 'while': 1627, 'white': 1628, 'who': 1629, 'whole': 1630, 'whose': 1631, 'why': 1632, 'wi': 1633, 'wieder': 1634, 'wife': 1635, 'wifi': 1636, 'wil': 1637, 'will': 1638, 'wiped': 1639, 'wired': 1640, 'wit': 1641, 'with': 1642, 'withou': 1643, 'without': 1644, 'wo': 1645, 'won': 1646, \"won't\": 1647, 'wondering': 1648, 'wor': 1649, 'word': 1650, 'words': 1651, 'work': 1652, 'worked': 1653, 'worki': 1654, 'workin': 1655, 'working': 1656, 'works': 1657, 'worm': 1658, 'worse': 1659, 'worst': 1660, 'wort': 1661, 'would': 1662, 'wrong': 1663, 'wtf': 1664, 'x': 1665, 'xcode': 1666, 'y': 1667, 'ya': 1668, 'yardımcı': 1669, 'yea': 1670, 'years': 1671, 'yes': 1672, 'yesterday': 1673, 'yet': 1674, 'yo': 1675, 'you': 1676, \"you've\": 1677, 'your': 1678, 'z': 1679, '~': 1680, '´': 1681, 'Écran': 1682, 'à': 1683, 'ı': 1684, 'все': 1685, 'д': 1686, 'нормально': 1687, '–': 1688, '—': 1689, '‘': 1690, '’': 1691, '“': 1692, '”': 1693, '•': 1694, '…': 1695, '⌚': 1696, '、': 1697, '。': 1698, 'このバグ直してーーー': 1699, 'は': 1700, 'ゲームも出来なくなったしアップデートしなきゃ良かった': 1701, 'コレは本当に困る': 1702, 'デバイス': 1703, '\\uf8ff': 1704, '️': 1705, '🏻': 1706, '🏼': 1707, '🏽': 1708, '👉': 1709, '👌': 1710, '👍': 1711, '📱': 1712, '😉': 1713, '😊': 1714, '😐': 1715, '😒': 1716, '😴': 1717, '😸': 1718, '🙃': 1719, '🙋': 1720, '🙏': 1721, '🤕': 1722, '🤗': 1723, '🤘': 1724, '🤨': 1725}\nencoder input\n[[[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n ...\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"#positional encoding\nfor line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n        encoder_input_data[line, timestep, input_features_dict[token]] = 1. \n\n    \n    for timestep, token in enumerate(target_doc.split()):\n        decoder_input_data[line, timestep, target_features_dict[token]] = 1. \n        if timestep > 0: \n            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.\nprint(pairs[:10])","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:23:11.719820Z","iopub.execute_input":"2022-12-23T09:23:11.721450Z","iopub.status.idle":"2022-12-23T09:23:11.890034Z","shell.execute_reply.started":"2022-12-23T09:23:11.721414Z","shell.execute_reply":"2022-12-23T09:23:11.888964Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[('  ', \" We're here for you. Which version of the iOS are you running? Check from Settings &gt; General &gt; About.\"), (' The newest update. I️ made sure t...', \" Lets take a closer look into this issue. Select the following link to join us in a DM and we'll go from there. \"), (' Tried resetting my settings .. re...', \" Let's go to DM for the next steps. DM us here: \"), (' This is what it looks like ', ' Any steps tried since it started last night?'), (' I️ have an iPhone 7 Plus and yes ...', \" That's great it has iOS 11.1 as we can rule out being outdated. Any steps tried since this started? Do you recall when it started?\"), (' I️ need answers because it’s anno...', \" We'd like to look into this with you. Which model do you have and is iOS 11.1 installed? Any steps tried so far?\"), ('Hey  and anyone else who upgraded ...', \" Hey, let's work together to figure out what's going on. Meet us in DM and we'll continue from there. \"), (' This is what is happening... ', \" We'd like to investigate further with you. Send us a DM and we can troubleshoot more from there. \"), ('Tf is wrong with my keyboard ', ' Fill us in on what is happening, then we can help out from there.'), (' are the call centres closed for t...', \" We've received your DM and will continue there.\")]\n","output_type":"stream"}]},{"cell_type":"code","source":"dimensionality = 256 \nbatch_size = 10 \nepochs = 600\n\n#Encoder\nencoder_inputs = Input(shape=(None, num_encoder_tokens))\nencoder_lstm = LSTM(dimensionality, return_state=True)\nencoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\nencoder_states = [state_hidden, state_cell]\n\n#Decoder\ndecoder_inputs = Input(shape=(None, num_decoder_tokens))\ndecoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\ndecoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n#Model\ntraining_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n#Compiling\ntraining_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n\n#Training\ntraining_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:23:11.891860Z","iopub.execute_input":"2022-12-23T09:23:11.892407Z","iopub.status.idle":"2022-12-23T09:40:19.454374Z","shell.execute_reply.started":"2022-12-23T09:23:11.892356Z","shell.execute_reply":"2022-12-23T09:40:19.453441Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2022-12-23 09:23:11.991971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-23 09:23:12.136209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-23 09:23:12.136978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-23 09:23:12.138479: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-23 09:23:12.138775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-23 09:23:12.139513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-23 09:23:12.140152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-23 09:23:14.283379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-23 09:23:14.284186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-23 09:23:14.284897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-23 09:23:14.285497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2022-12-23 09:23:16.912097: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/600\n","output_type":"stream"},{"name":"stderr","text":"2022-12-23 09:23:20.430535: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"80/80 [==============================] - 8s 34ms/step - loss: 1.8193 - accuracy: 0.0247 - val_loss: 1.6815 - val_accuracy: 0.0262\nEpoch 2/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.7600 - accuracy: 0.0270 - val_loss: 1.6687 - val_accuracy: 0.0256\nEpoch 3/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.7428 - accuracy: 0.0277 - val_loss: 1.6655 - val_accuracy: 0.0279\nEpoch 4/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.7306 - accuracy: 0.0285 - val_loss: 1.6667 - val_accuracy: 0.0264\nEpoch 5/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.7204 - accuracy: 0.0287 - val_loss: 1.6659 - val_accuracy: 0.0289\nEpoch 6/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.7136 - accuracy: 0.0291 - val_loss: 1.6662 - val_accuracy: 0.0273\nEpoch 7/600\n80/80 [==============================] - 2s 23ms/step - loss: 1.7034 - accuracy: 0.0292 - val_loss: 1.6734 - val_accuracy: 0.0340\nEpoch 8/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.6973 - accuracy: 0.0302 - val_loss: 1.6914 - val_accuracy: 0.0292\nEpoch 9/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.6923 - accuracy: 0.0304 - val_loss: 1.6634 - val_accuracy: 0.0315\nEpoch 10/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.6846 - accuracy: 0.0315 - val_loss: 1.6571 - val_accuracy: 0.0302\nEpoch 11/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.6786 - accuracy: 0.0330 - val_loss: 1.6556 - val_accuracy: 0.0320\nEpoch 12/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.6745 - accuracy: 0.0337 - val_loss: 1.6558 - val_accuracy: 0.0326\nEpoch 13/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.6635 - accuracy: 0.0342 - val_loss: 1.6756 - val_accuracy: 0.0325\nEpoch 14/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.6584 - accuracy: 0.0351 - val_loss: 1.6387 - val_accuracy: 0.0342\nEpoch 15/600\n80/80 [==============================] - 2s 23ms/step - loss: 1.6501 - accuracy: 0.0354 - val_loss: 1.6354 - val_accuracy: 0.0356\nEpoch 16/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.6393 - accuracy: 0.0373 - val_loss: 1.6259 - val_accuracy: 0.0381\nEpoch 17/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.6279 - accuracy: 0.0393 - val_loss: 1.6227 - val_accuracy: 0.0390\nEpoch 18/600\n80/80 [==============================] - 2s 23ms/step - loss: 1.6237 - accuracy: 0.0411 - val_loss: 1.6202 - val_accuracy: 0.0420\nEpoch 19/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.6085 - accuracy: 0.0428 - val_loss: 1.6123 - val_accuracy: 0.0385\nEpoch 20/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.5959 - accuracy: 0.0456 - val_loss: 1.6249 - val_accuracy: 0.0335\nEpoch 21/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.5814 - accuracy: 0.0479 - val_loss: 1.5958 - val_accuracy: 0.0377\nEpoch 22/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.5734 - accuracy: 0.0499 - val_loss: 1.5846 - val_accuracy: 0.0462\nEpoch 23/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.5656 - accuracy: 0.0511 - val_loss: 1.5864 - val_accuracy: 0.0454\nEpoch 24/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.5470 - accuracy: 0.0543 - val_loss: 1.5873 - val_accuracy: 0.0461\nEpoch 25/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.5482 - accuracy: 0.0553 - val_loss: 1.5760 - val_accuracy: 0.0520\nEpoch 26/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.5251 - accuracy: 0.0583 - val_loss: 1.5719 - val_accuracy: 0.0546\nEpoch 27/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.5114 - accuracy: 0.0614 - val_loss: 1.5865 - val_accuracy: 0.0456\nEpoch 28/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.4985 - accuracy: 0.0623 - val_loss: 1.5575 - val_accuracy: 0.0534\nEpoch 29/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.4912 - accuracy: 0.0641 - val_loss: 1.5543 - val_accuracy: 0.0538\nEpoch 30/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.4777 - accuracy: 0.0659 - val_loss: 1.5385 - val_accuracy: 0.0599\nEpoch 31/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.4620 - accuracy: 0.0677 - val_loss: 1.5390 - val_accuracy: 0.0570\nEpoch 32/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.4520 - accuracy: 0.0689 - val_loss: 1.5448 - val_accuracy: 0.0582\nEpoch 33/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.4388 - accuracy: 0.0701 - val_loss: 1.5346 - val_accuracy: 0.0582\nEpoch 34/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.4142 - accuracy: 0.0737 - val_loss: 1.5158 - val_accuracy: 0.0598\nEpoch 35/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.4052 - accuracy: 0.0753 - val_loss: 1.5108 - val_accuracy: 0.0636\nEpoch 36/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.3905 - accuracy: 0.0776 - val_loss: 1.5061 - val_accuracy: 0.0584\nEpoch 37/600\n80/80 [==============================] - 2s 23ms/step - loss: 1.3712 - accuracy: 0.0791 - val_loss: 1.4873 - val_accuracy: 0.0634\nEpoch 38/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.3592 - accuracy: 0.0816 - val_loss: 1.4836 - val_accuracy: 0.0645\nEpoch 39/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.3502 - accuracy: 0.0827 - val_loss: 1.4787 - val_accuracy: 0.0690\nEpoch 40/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.3254 - accuracy: 0.0858 - val_loss: 1.4667 - val_accuracy: 0.0661\nEpoch 41/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.3135 - accuracy: 0.0877 - val_loss: 1.4940 - val_accuracy: 0.0620\nEpoch 42/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.2979 - accuracy: 0.0911 - val_loss: 1.4543 - val_accuracy: 0.0713\nEpoch 43/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.2877 - accuracy: 0.0925 - val_loss: 1.4557 - val_accuracy: 0.0665\nEpoch 44/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.3037 - accuracy: 0.0895 - val_loss: 1.4857 - val_accuracy: 0.0604\nEpoch 45/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.2645 - accuracy: 0.0950 - val_loss: 1.4413 - val_accuracy: 0.0691\nEpoch 46/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.2587 - accuracy: 0.0967 - val_loss: 1.4546 - val_accuracy: 0.0651\nEpoch 47/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.2427 - accuracy: 0.0977 - val_loss: 1.4576 - val_accuracy: 0.0656\nEpoch 48/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.2316 - accuracy: 0.1009 - val_loss: 1.4401 - val_accuracy: 0.0704\nEpoch 49/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.2175 - accuracy: 0.1019 - val_loss: 1.4269 - val_accuracy: 0.0754\nEpoch 50/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.2010 - accuracy: 0.1056 - val_loss: 1.4352 - val_accuracy: 0.0751\nEpoch 51/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.1888 - accuracy: 0.1073 - val_loss: 1.4425 - val_accuracy: 0.0727\nEpoch 52/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.1792 - accuracy: 0.1100 - val_loss: 1.4338 - val_accuracy: 0.0746\nEpoch 53/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.1780 - accuracy: 0.1084 - val_loss: 1.4046 - val_accuracy: 0.0785\nEpoch 54/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.1472 - accuracy: 0.1149 - val_loss: 1.4207 - val_accuracy: 0.0777\nEpoch 55/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.1425 - accuracy: 0.1156 - val_loss: 1.3814 - val_accuracy: 0.0798\nEpoch 56/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.1280 - accuracy: 0.1170 - val_loss: 1.4087 - val_accuracy: 0.0761\nEpoch 57/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.1151 - accuracy: 0.1186 - val_loss: 1.4114 - val_accuracy: 0.0764\nEpoch 58/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.1120 - accuracy: 0.1202 - val_loss: 1.4200 - val_accuracy: 0.0769\nEpoch 59/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.1006 - accuracy: 0.1219 - val_loss: 1.3900 - val_accuracy: 0.0813\nEpoch 60/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.0859 - accuracy: 0.1241 - val_loss: 1.4031 - val_accuracy: 0.0761\nEpoch 61/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.0814 - accuracy: 0.1242 - val_loss: 1.3857 - val_accuracy: 0.0813\nEpoch 62/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.0639 - accuracy: 0.1274 - val_loss: 1.3676 - val_accuracy: 0.0821\nEpoch 63/600\n80/80 [==============================] - 2s 21ms/step - loss: 1.0548 - accuracy: 0.1273 - val_loss: 1.3996 - val_accuracy: 0.0770\nEpoch 64/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.0540 - accuracy: 0.1286 - val_loss: 1.3728 - val_accuracy: 0.0846\nEpoch 65/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.0452 - accuracy: 0.1286 - val_loss: 1.3599 - val_accuracy: 0.0869\nEpoch 66/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.0413 - accuracy: 0.1294 - val_loss: 1.3670 - val_accuracy: 0.0833\nEpoch 67/600\n80/80 [==============================] - 2s 20ms/step - loss: 1.0147 - accuracy: 0.1352 - val_loss: 1.3718 - val_accuracy: 0.0823\nEpoch 68/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.0081 - accuracy: 0.1353 - val_loss: 1.3730 - val_accuracy: 0.0813\nEpoch 69/600\n80/80 [==============================] - 2s 22ms/step - loss: 1.0073 - accuracy: 0.1351 - val_loss: 1.3605 - val_accuracy: 0.0820\nEpoch 70/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.9848 - accuracy: 0.1396 - val_loss: 1.3589 - val_accuracy: 0.0842\nEpoch 71/600\n80/80 [==============================] - 2s 24ms/step - loss: 0.9759 - accuracy: 0.1402 - val_loss: 1.3625 - val_accuracy: 0.0874\nEpoch 72/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.9706 - accuracy: 0.1432 - val_loss: 1.3518 - val_accuracy: 0.0842\nEpoch 73/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.9760 - accuracy: 0.1417 - val_loss: 1.3531 - val_accuracy: 0.0846\nEpoch 74/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.9703 - accuracy: 0.1418 - val_loss: 1.3622 - val_accuracy: 0.0865\nEpoch 75/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.9459 - accuracy: 0.1467 - val_loss: 1.3526 - val_accuracy: 0.0835\nEpoch 76/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.9318 - accuracy: 0.1486 - val_loss: 1.3459 - val_accuracy: 0.0858\nEpoch 77/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.9284 - accuracy: 0.1490 - val_loss: 1.3690 - val_accuracy: 0.0820\nEpoch 78/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.9196 - accuracy: 0.1500 - val_loss: 1.3508 - val_accuracy: 0.0882\nEpoch 79/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.9122 - accuracy: 0.1515 - val_loss: 1.3432 - val_accuracy: 0.0870\nEpoch 80/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.8995 - accuracy: 0.1538 - val_loss: 1.3525 - val_accuracy: 0.0882\nEpoch 81/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.9020 - accuracy: 0.1534 - val_loss: 1.3779 - val_accuracy: 0.0806\nEpoch 82/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.8870 - accuracy: 0.1558 - val_loss: 1.3592 - val_accuracy: 0.0870\nEpoch 83/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.8830 - accuracy: 0.1566 - val_loss: 1.3426 - val_accuracy: 0.0869\nEpoch 84/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.8691 - accuracy: 0.1595 - val_loss: 1.3445 - val_accuracy: 0.0908\nEpoch 85/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.8600 - accuracy: 0.1610 - val_loss: 1.3275 - val_accuracy: 0.0890\nEpoch 86/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.8645 - accuracy: 0.1595 - val_loss: 1.3437 - val_accuracy: 0.0882\nEpoch 87/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.8635 - accuracy: 0.1606 - val_loss: 1.3516 - val_accuracy: 0.0839\nEpoch 88/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.8458 - accuracy: 0.1640 - val_loss: 1.3500 - val_accuracy: 0.0848\nEpoch 89/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.8366 - accuracy: 0.1652 - val_loss: 1.3514 - val_accuracy: 0.0868\nEpoch 90/600\n80/80 [==============================] - 2s 24ms/step - loss: 0.8319 - accuracy: 0.1665 - val_loss: 1.3444 - val_accuracy: 0.0903\nEpoch 91/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.8178 - accuracy: 0.1689 - val_loss: 1.3538 - val_accuracy: 0.0863\nEpoch 92/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.8122 - accuracy: 0.1683 - val_loss: 1.3418 - val_accuracy: 0.0865\nEpoch 93/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.8071 - accuracy: 0.1695 - val_loss: 1.3467 - val_accuracy: 0.0855\nEpoch 94/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.7991 - accuracy: 0.1703 - val_loss: 1.3489 - val_accuracy: 0.0851\nEpoch 95/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.7896 - accuracy: 0.1738 - val_loss: 1.3603 - val_accuracy: 0.0815\nEpoch 96/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.7845 - accuracy: 0.1748 - val_loss: 1.3588 - val_accuracy: 0.0894\nEpoch 97/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.7785 - accuracy: 0.1772 - val_loss: 1.3381 - val_accuracy: 0.0915\nEpoch 98/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.7717 - accuracy: 0.1783 - val_loss: 1.3759 - val_accuracy: 0.0863\nEpoch 99/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.7616 - accuracy: 0.1812 - val_loss: 1.3565 - val_accuracy: 0.0887\nEpoch 100/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.7582 - accuracy: 0.1802 - val_loss: 1.3365 - val_accuracy: 0.0935\nEpoch 101/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.7479 - accuracy: 0.1844 - val_loss: 1.3770 - val_accuracy: 0.0852\nEpoch 102/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.7495 - accuracy: 0.1842 - val_loss: 1.3595 - val_accuracy: 0.0901\nEpoch 103/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.7392 - accuracy: 0.1867 - val_loss: 1.3408 - val_accuracy: 0.0877\nEpoch 104/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.7301 - accuracy: 0.1873 - val_loss: 1.3435 - val_accuracy: 0.0863\nEpoch 105/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.7248 - accuracy: 0.1880 - val_loss: 1.3541 - val_accuracy: 0.0885\nEpoch 106/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.7184 - accuracy: 0.1904 - val_loss: 1.3706 - val_accuracy: 0.0882\nEpoch 107/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.7188 - accuracy: 0.1905 - val_loss: 1.3459 - val_accuracy: 0.0914\nEpoch 108/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.7142 - accuracy: 0.1904 - val_loss: 1.3573 - val_accuracy: 0.0860\nEpoch 109/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.7066 - accuracy: 0.1937 - val_loss: 1.3780 - val_accuracy: 0.0837\nEpoch 110/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.6959 - accuracy: 0.1955 - val_loss: 1.3592 - val_accuracy: 0.0903\nEpoch 111/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.6914 - accuracy: 0.1952 - val_loss: 1.3553 - val_accuracy: 0.0903\nEpoch 112/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.6772 - accuracy: 0.1988 - val_loss: 1.3732 - val_accuracy: 0.0890\nEpoch 113/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.6872 - accuracy: 0.1977 - val_loss: 1.3623 - val_accuracy: 0.0898\nEpoch 114/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.6626 - accuracy: 0.2030 - val_loss: 1.3586 - val_accuracy: 0.0870\nEpoch 115/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.6672 - accuracy: 0.2012 - val_loss: 1.3652 - val_accuracy: 0.0851\nEpoch 116/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.6584 - accuracy: 0.2034 - val_loss: 1.3633 - val_accuracy: 0.0857\nEpoch 117/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.6520 - accuracy: 0.2041 - val_loss: 1.3521 - val_accuracy: 0.0910\nEpoch 118/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.6554 - accuracy: 0.2050 - val_loss: 1.3730 - val_accuracy: 0.0873\nEpoch 119/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.6399 - accuracy: 0.2088 - val_loss: 1.3587 - val_accuracy: 0.0899\nEpoch 120/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.6423 - accuracy: 0.2063 - val_loss: 1.3574 - val_accuracy: 0.0878\nEpoch 121/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.6464 - accuracy: 0.2058 - val_loss: 1.3651 - val_accuracy: 0.0893\nEpoch 122/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.6327 - accuracy: 0.2084 - val_loss: 1.3559 - val_accuracy: 0.0919\nEpoch 123/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.6247 - accuracy: 0.2119 - val_loss: 1.3716 - val_accuracy: 0.0839\nEpoch 124/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.6306 - accuracy: 0.2108 - val_loss: 1.3696 - val_accuracy: 0.0881\nEpoch 125/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.6064 - accuracy: 0.2166 - val_loss: 1.3721 - val_accuracy: 0.0905\nEpoch 126/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.6140 - accuracy: 0.2150 - val_loss: 1.3744 - val_accuracy: 0.0896\nEpoch 127/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.6053 - accuracy: 0.2147 - val_loss: 1.3736 - val_accuracy: 0.0889\nEpoch 128/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.5965 - accuracy: 0.2163 - val_loss: 1.3606 - val_accuracy: 0.0862\nEpoch 129/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.5939 - accuracy: 0.2177 - val_loss: 1.3821 - val_accuracy: 0.0893\nEpoch 130/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.5863 - accuracy: 0.2205 - val_loss: 1.3742 - val_accuracy: 0.0865\nEpoch 131/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5882 - accuracy: 0.2184 - val_loss: 1.3843 - val_accuracy: 0.0875\nEpoch 132/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.6028 - accuracy: 0.2152 - val_loss: 1.3790 - val_accuracy: 0.0849\nEpoch 133/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5722 - accuracy: 0.2225 - val_loss: 1.3953 - val_accuracy: 0.0858\nEpoch 134/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5748 - accuracy: 0.2229 - val_loss: 1.3881 - val_accuracy: 0.0892\nEpoch 135/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.5723 - accuracy: 0.2241 - val_loss: 1.3840 - val_accuracy: 0.0855\nEpoch 136/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5704 - accuracy: 0.2220 - val_loss: 1.3795 - val_accuracy: 0.0885\nEpoch 137/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5716 - accuracy: 0.2232 - val_loss: 1.3840 - val_accuracy: 0.0828\nEpoch 138/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5648 - accuracy: 0.2251 - val_loss: 1.3914 - val_accuracy: 0.0884\nEpoch 139/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.5594 - accuracy: 0.2271 - val_loss: 1.3936 - val_accuracy: 0.0841\nEpoch 140/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.5476 - accuracy: 0.2293 - val_loss: 1.3908 - val_accuracy: 0.0840\nEpoch 141/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.5411 - accuracy: 0.2305 - val_loss: 1.4001 - val_accuracy: 0.0870\nEpoch 142/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5400 - accuracy: 0.2311 - val_loss: 1.3970 - val_accuracy: 0.0877\nEpoch 143/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5346 - accuracy: 0.2313 - val_loss: 1.3874 - val_accuracy: 0.0844\nEpoch 144/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5368 - accuracy: 0.2296 - val_loss: 1.3886 - val_accuracy: 0.0879\nEpoch 145/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.5261 - accuracy: 0.2340 - val_loss: 1.3856 - val_accuracy: 0.0843\nEpoch 146/600\n80/80 [==============================] - 2s 24ms/step - loss: 0.5324 - accuracy: 0.2320 - val_loss: 1.4095 - val_accuracy: 0.0863\nEpoch 147/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5173 - accuracy: 0.2359 - val_loss: 1.4012 - val_accuracy: 0.0837\nEpoch 148/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.5178 - accuracy: 0.2368 - val_loss: 1.3943 - val_accuracy: 0.0848\nEpoch 149/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5113 - accuracy: 0.2377 - val_loss: 1.3888 - val_accuracy: 0.0894\nEpoch 150/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.5092 - accuracy: 0.2381 - val_loss: 1.4151 - val_accuracy: 0.0852\nEpoch 151/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.5118 - accuracy: 0.2376 - val_loss: 1.4075 - val_accuracy: 0.0868\nEpoch 152/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.5094 - accuracy: 0.2373 - val_loss: 1.4044 - val_accuracy: 0.0842\nEpoch 153/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4966 - accuracy: 0.2411 - val_loss: 1.3939 - val_accuracy: 0.0887\nEpoch 154/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.5022 - accuracy: 0.2386 - val_loss: 1.4061 - val_accuracy: 0.0882\nEpoch 155/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4919 - accuracy: 0.2415 - val_loss: 1.4142 - val_accuracy: 0.0828\nEpoch 156/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4903 - accuracy: 0.2420 - val_loss: 1.4233 - val_accuracy: 0.0866\nEpoch 157/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4839 - accuracy: 0.2440 - val_loss: 1.4045 - val_accuracy: 0.0884\nEpoch 158/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4797 - accuracy: 0.2442 - val_loss: 1.4053 - val_accuracy: 0.0867\nEpoch 159/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4768 - accuracy: 0.2456 - val_loss: 1.4042 - val_accuracy: 0.0876\nEpoch 160/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4744 - accuracy: 0.2466 - val_loss: 1.4080 - val_accuracy: 0.0856\nEpoch 161/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.4730 - accuracy: 0.2476 - val_loss: 1.4164 - val_accuracy: 0.0849\nEpoch 162/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4706 - accuracy: 0.2455 - val_loss: 1.4108 - val_accuracy: 0.0847\nEpoch 163/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4632 - accuracy: 0.2483 - val_loss: 1.4076 - val_accuracy: 0.0915\nEpoch 164/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4610 - accuracy: 0.2504 - val_loss: 1.4331 - val_accuracy: 0.0821\nEpoch 165/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4592 - accuracy: 0.2508 - val_loss: 1.4327 - val_accuracy: 0.0829\nEpoch 166/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4531 - accuracy: 0.2492 - val_loss: 1.4438 - val_accuracy: 0.0821\nEpoch 167/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.4497 - accuracy: 0.2518 - val_loss: 1.4255 - val_accuracy: 0.0839\nEpoch 168/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4554 - accuracy: 0.2505 - val_loss: 1.4133 - val_accuracy: 0.0894\nEpoch 169/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4421 - accuracy: 0.2531 - val_loss: 1.4223 - val_accuracy: 0.0870\nEpoch 170/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4479 - accuracy: 0.2532 - val_loss: 1.4219 - val_accuracy: 0.0891\nEpoch 171/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4430 - accuracy: 0.2550 - val_loss: 1.4256 - val_accuracy: 0.0838\nEpoch 172/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4421 - accuracy: 0.2540 - val_loss: 1.4313 - val_accuracy: 0.0861\nEpoch 173/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4313 - accuracy: 0.2563 - val_loss: 1.4403 - val_accuracy: 0.0865\nEpoch 174/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.4282 - accuracy: 0.2565 - val_loss: 1.4187 - val_accuracy: 0.0898\nEpoch 175/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4246 - accuracy: 0.2581 - val_loss: 1.4457 - val_accuracy: 0.0830\nEpoch 176/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4311 - accuracy: 0.2549 - val_loss: 1.4430 - val_accuracy: 0.0826\nEpoch 177/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4268 - accuracy: 0.2553 - val_loss: 1.4374 - val_accuracy: 0.0826\nEpoch 178/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4206 - accuracy: 0.2569 - val_loss: 1.4379 - val_accuracy: 0.0842\nEpoch 179/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4224 - accuracy: 0.2563 - val_loss: 1.4434 - val_accuracy: 0.0830\nEpoch 180/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4141 - accuracy: 0.2592 - val_loss: 1.4374 - val_accuracy: 0.0879\nEpoch 181/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4147 - accuracy: 0.2594 - val_loss: 1.4443 - val_accuracy: 0.0835\nEpoch 182/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4107 - accuracy: 0.2601 - val_loss: 1.4404 - val_accuracy: 0.0830\nEpoch 183/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4078 - accuracy: 0.2609 - val_loss: 1.4412 - val_accuracy: 0.0828\nEpoch 184/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.4097 - accuracy: 0.2601 - val_loss: 1.4351 - val_accuracy: 0.0888\nEpoch 185/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4094 - accuracy: 0.2598 - val_loss: 1.4481 - val_accuracy: 0.0851\nEpoch 186/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.4003 - accuracy: 0.2617 - val_loss: 1.4466 - val_accuracy: 0.0830\nEpoch 187/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.3983 - accuracy: 0.2606 - val_loss: 1.4533 - val_accuracy: 0.0809\nEpoch 188/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.4037 - accuracy: 0.2606 - val_loss: 1.4495 - val_accuracy: 0.0829\nEpoch 189/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3951 - accuracy: 0.2618 - val_loss: 1.4418 - val_accuracy: 0.0885\nEpoch 190/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3929 - accuracy: 0.2640 - val_loss: 1.4477 - val_accuracy: 0.0865\nEpoch 191/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3848 - accuracy: 0.2646 - val_loss: 1.4375 - val_accuracy: 0.0861\nEpoch 192/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3871 - accuracy: 0.2635 - val_loss: 1.4631 - val_accuracy: 0.0825\nEpoch 193/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3844 - accuracy: 0.2648 - val_loss: 1.4484 - val_accuracy: 0.0834\nEpoch 194/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3860 - accuracy: 0.2645 - val_loss: 1.4643 - val_accuracy: 0.0811\nEpoch 195/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3792 - accuracy: 0.2657 - val_loss: 1.4498 - val_accuracy: 0.0875\nEpoch 196/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3814 - accuracy: 0.2652 - val_loss: 1.4656 - val_accuracy: 0.0838\nEpoch 197/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3779 - accuracy: 0.2672 - val_loss: 1.4488 - val_accuracy: 0.0892\nEpoch 198/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3758 - accuracy: 0.2681 - val_loss: 1.4569 - val_accuracy: 0.0868\nEpoch 199/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3717 - accuracy: 0.2676 - val_loss: 1.4462 - val_accuracy: 0.0872\nEpoch 200/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.3704 - accuracy: 0.2684 - val_loss: 1.4678 - val_accuracy: 0.0860\nEpoch 201/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3668 - accuracy: 0.2699 - val_loss: 1.4628 - val_accuracy: 0.0836\nEpoch 202/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.3691 - accuracy: 0.2683 - val_loss: 1.4690 - val_accuracy: 0.0827\nEpoch 203/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3753 - accuracy: 0.2668 - val_loss: 1.4553 - val_accuracy: 0.0845\nEpoch 204/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3604 - accuracy: 0.2698 - val_loss: 1.4680 - val_accuracy: 0.0864\nEpoch 205/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3608 - accuracy: 0.2698 - val_loss: 1.4655 - val_accuracy: 0.0843\nEpoch 206/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.3726 - accuracy: 0.2673 - val_loss: 1.4743 - val_accuracy: 0.0826\nEpoch 207/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3529 - accuracy: 0.2718 - val_loss: 1.4769 - val_accuracy: 0.0824\nEpoch 208/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3531 - accuracy: 0.2710 - val_loss: 1.4724 - val_accuracy: 0.0830\nEpoch 209/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3546 - accuracy: 0.2707 - val_loss: 1.4829 - val_accuracy: 0.0832\nEpoch 210/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3568 - accuracy: 0.2700 - val_loss: 1.4604 - val_accuracy: 0.0845\nEpoch 211/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3520 - accuracy: 0.2711 - val_loss: 1.4649 - val_accuracy: 0.0864\nEpoch 212/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3463 - accuracy: 0.2732 - val_loss: 1.4681 - val_accuracy: 0.0862\nEpoch 213/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.3451 - accuracy: 0.2738 - val_loss: 1.4703 - val_accuracy: 0.0882\nEpoch 214/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3443 - accuracy: 0.2737 - val_loss: 1.4896 - val_accuracy: 0.0869\nEpoch 215/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3615 - accuracy: 0.2694 - val_loss: 1.4853 - val_accuracy: 0.0823\nEpoch 216/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3396 - accuracy: 0.2747 - val_loss: 1.4749 - val_accuracy: 0.0851\nEpoch 217/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3365 - accuracy: 0.2744 - val_loss: 1.4803 - val_accuracy: 0.0825\nEpoch 218/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3409 - accuracy: 0.2740 - val_loss: 1.4773 - val_accuracy: 0.0844\nEpoch 219/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3573 - accuracy: 0.2694 - val_loss: 1.4685 - val_accuracy: 0.0866\nEpoch 220/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3322 - accuracy: 0.2760 - val_loss: 1.4874 - val_accuracy: 0.0829\nEpoch 221/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3378 - accuracy: 0.2735 - val_loss: 1.4877 - val_accuracy: 0.0849\nEpoch 222/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3366 - accuracy: 0.2750 - val_loss: 1.4862 - val_accuracy: 0.0833\nEpoch 223/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3292 - accuracy: 0.2770 - val_loss: 1.4794 - val_accuracy: 0.0887\nEpoch 224/600\n80/80 [==============================] - 2s 24ms/step - loss: 0.3370 - accuracy: 0.2751 - val_loss: 1.4739 - val_accuracy: 0.0854\nEpoch 225/600\n80/80 [==============================] - 2s 24ms/step - loss: 0.3332 - accuracy: 0.2754 - val_loss: 1.4811 - val_accuracy: 0.0878\nEpoch 226/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.3232 - accuracy: 0.2783 - val_loss: 1.4832 - val_accuracy: 0.0878\nEpoch 227/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3230 - accuracy: 0.2777 - val_loss: 1.4886 - val_accuracy: 0.0855\nEpoch 228/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3224 - accuracy: 0.2775 - val_loss: 1.4806 - val_accuracy: 0.0849\nEpoch 229/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3224 - accuracy: 0.2776 - val_loss: 1.4975 - val_accuracy: 0.0878\nEpoch 230/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3259 - accuracy: 0.2771 - val_loss: 1.4781 - val_accuracy: 0.0851\nEpoch 231/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3287 - accuracy: 0.2757 - val_loss: 1.4939 - val_accuracy: 0.0809\nEpoch 232/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.3255 - accuracy: 0.2768 - val_loss: 1.4998 - val_accuracy: 0.0870\nEpoch 233/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3124 - accuracy: 0.2793 - val_loss: 1.4940 - val_accuracy: 0.0835\nEpoch 234/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3137 - accuracy: 0.2788 - val_loss: 1.4984 - val_accuracy: 0.0815\nEpoch 235/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3151 - accuracy: 0.2789 - val_loss: 1.5079 - val_accuracy: 0.0821\nEpoch 236/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3137 - accuracy: 0.2782 - val_loss: 1.5064 - val_accuracy: 0.0864\nEpoch 237/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3159 - accuracy: 0.2785 - val_loss: 1.4928 - val_accuracy: 0.0831\nEpoch 238/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3221 - accuracy: 0.2770 - val_loss: 1.5060 - val_accuracy: 0.0812\nEpoch 239/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3072 - accuracy: 0.2793 - val_loss: 1.4862 - val_accuracy: 0.0863\nEpoch 240/600\n80/80 [==============================] - 2s 24ms/step - loss: 0.3066 - accuracy: 0.2796 - val_loss: 1.4966 - val_accuracy: 0.0837\nEpoch 241/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3084 - accuracy: 0.2790 - val_loss: 1.4908 - val_accuracy: 0.0817\nEpoch 242/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3022 - accuracy: 0.2813 - val_loss: 1.4867 - val_accuracy: 0.0892\nEpoch 243/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3047 - accuracy: 0.2805 - val_loss: 1.5024 - val_accuracy: 0.0823\nEpoch 244/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.3023 - accuracy: 0.2809 - val_loss: 1.5006 - val_accuracy: 0.0824\nEpoch 245/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.3081 - accuracy: 0.2807 - val_loss: 1.4967 - val_accuracy: 0.0877\nEpoch 246/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3041 - accuracy: 0.2811 - val_loss: 1.4968 - val_accuracy: 0.0844\nEpoch 247/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2984 - accuracy: 0.2816 - val_loss: 1.5024 - val_accuracy: 0.0832\nEpoch 248/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2981 - accuracy: 0.2818 - val_loss: 1.4968 - val_accuracy: 0.0843\nEpoch 249/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2961 - accuracy: 0.2811 - val_loss: 1.5030 - val_accuracy: 0.0849\nEpoch 250/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.3012 - accuracy: 0.2809 - val_loss: 1.4999 - val_accuracy: 0.0872\nEpoch 251/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2896 - accuracy: 0.2837 - val_loss: 1.5182 - val_accuracy: 0.0854\nEpoch 252/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2930 - accuracy: 0.2825 - val_loss: 1.5128 - val_accuracy: 0.0851\nEpoch 253/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2972 - accuracy: 0.2813 - val_loss: 1.5051 - val_accuracy: 0.0843\nEpoch 254/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2948 - accuracy: 0.2815 - val_loss: 1.5072 - val_accuracy: 0.0842\nEpoch 255/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2940 - accuracy: 0.2816 - val_loss: 1.4947 - val_accuracy: 0.0848\nEpoch 256/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2914 - accuracy: 0.2821 - val_loss: 1.5006 - val_accuracy: 0.0870\nEpoch 257/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2942 - accuracy: 0.2820 - val_loss: 1.5019 - val_accuracy: 0.0837\nEpoch 258/600\n80/80 [==============================] - 2s 24ms/step - loss: 0.2857 - accuracy: 0.2834 - val_loss: 1.5088 - val_accuracy: 0.0847\nEpoch 259/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2849 - accuracy: 0.2830 - val_loss: 1.5014 - val_accuracy: 0.0852\nEpoch 260/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2874 - accuracy: 0.2831 - val_loss: 1.5035 - val_accuracy: 0.0856\nEpoch 261/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2848 - accuracy: 0.2836 - val_loss: 1.5006 - val_accuracy: 0.0860\nEpoch 262/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2869 - accuracy: 0.2827 - val_loss: 1.5126 - val_accuracy: 0.0843\nEpoch 263/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2803 - accuracy: 0.2836 - val_loss: 1.5187 - val_accuracy: 0.0848\nEpoch 264/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2819 - accuracy: 0.2835 - val_loss: 1.5112 - val_accuracy: 0.0833\nEpoch 265/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2800 - accuracy: 0.2842 - val_loss: 1.5299 - val_accuracy: 0.0843\nEpoch 266/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2824 - accuracy: 0.2837 - val_loss: 1.4952 - val_accuracy: 0.0851\nEpoch 267/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2792 - accuracy: 0.2844 - val_loss: 1.5193 - val_accuracy: 0.0843\nEpoch 268/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2793 - accuracy: 0.2841 - val_loss: 1.5135 - val_accuracy: 0.0856\nEpoch 269/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2822 - accuracy: 0.2837 - val_loss: 1.5157 - val_accuracy: 0.0840\nEpoch 270/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2798 - accuracy: 0.2847 - val_loss: 1.5045 - val_accuracy: 0.0870\nEpoch 271/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2698 - accuracy: 0.2865 - val_loss: 1.5181 - val_accuracy: 0.0846\nEpoch 272/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2761 - accuracy: 0.2851 - val_loss: 1.5141 - val_accuracy: 0.0827\nEpoch 273/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2767 - accuracy: 0.2849 - val_loss: 1.5279 - val_accuracy: 0.0826\nEpoch 274/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2745 - accuracy: 0.2852 - val_loss: 1.5141 - val_accuracy: 0.0820\nEpoch 275/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2748 - accuracy: 0.2853 - val_loss: 1.5214 - val_accuracy: 0.0840\nEpoch 276/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2722 - accuracy: 0.2857 - val_loss: 1.5367 - val_accuracy: 0.0807\nEpoch 277/600\n80/80 [==============================] - 2s 25ms/step - loss: 0.2702 - accuracy: 0.2864 - val_loss: 1.5275 - val_accuracy: 0.0834\nEpoch 278/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2689 - accuracy: 0.2867 - val_loss: 1.5104 - val_accuracy: 0.0869\nEpoch 279/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2683 - accuracy: 0.2862 - val_loss: 1.5234 - val_accuracy: 0.0882\nEpoch 280/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2924 - accuracy: 0.2811 - val_loss: 1.5159 - val_accuracy: 0.0851\nEpoch 281/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2640 - accuracy: 0.2873 - val_loss: 1.5171 - val_accuracy: 0.0846\nEpoch 282/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2661 - accuracy: 0.2868 - val_loss: 1.5311 - val_accuracy: 0.0835\nEpoch 283/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2648 - accuracy: 0.2867 - val_loss: 1.5154 - val_accuracy: 0.0873\nEpoch 284/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2672 - accuracy: 0.2868 - val_loss: 1.5120 - val_accuracy: 0.0846\nEpoch 285/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2640 - accuracy: 0.2877 - val_loss: 1.5308 - val_accuracy: 0.0846\nEpoch 286/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2641 - accuracy: 0.2879 - val_loss: 1.5237 - val_accuracy: 0.0837\nEpoch 287/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2613 - accuracy: 0.2879 - val_loss: 1.5276 - val_accuracy: 0.0832\nEpoch 288/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2613 - accuracy: 0.2873 - val_loss: 1.5156 - val_accuracy: 0.0856\nEpoch 289/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2634 - accuracy: 0.2868 - val_loss: 1.5164 - val_accuracy: 0.0856\nEpoch 290/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2604 - accuracy: 0.2875 - val_loss: 1.5260 - val_accuracy: 0.0851\nEpoch 291/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2571 - accuracy: 0.2878 - val_loss: 1.5325 - val_accuracy: 0.0846\nEpoch 292/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2608 - accuracy: 0.2870 - val_loss: 1.5229 - val_accuracy: 0.0862\nEpoch 293/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2564 - accuracy: 0.2880 - val_loss: 1.5243 - val_accuracy: 0.0842\nEpoch 294/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2596 - accuracy: 0.2875 - val_loss: 1.5316 - val_accuracy: 0.0849\nEpoch 295/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2575 - accuracy: 0.2872 - val_loss: 1.5389 - val_accuracy: 0.0806\nEpoch 296/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2562 - accuracy: 0.2874 - val_loss: 1.5327 - val_accuracy: 0.0835\nEpoch 297/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2551 - accuracy: 0.2886 - val_loss: 1.5254 - val_accuracy: 0.0838\nEpoch 298/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2540 - accuracy: 0.2881 - val_loss: 1.5343 - val_accuracy: 0.0844\nEpoch 299/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2583 - accuracy: 0.2876 - val_loss: 1.5328 - val_accuracy: 0.0834\nEpoch 300/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2499 - accuracy: 0.2887 - val_loss: 1.5159 - val_accuracy: 0.0850\nEpoch 301/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2509 - accuracy: 0.2881 - val_loss: 1.5313 - val_accuracy: 0.0851\nEpoch 302/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2521 - accuracy: 0.2887 - val_loss: 1.5307 - val_accuracy: 0.0835\nEpoch 303/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2514 - accuracy: 0.2889 - val_loss: 1.5413 - val_accuracy: 0.0835\nEpoch 304/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2480 - accuracy: 0.2894 - val_loss: 1.5481 - val_accuracy: 0.0827\nEpoch 305/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2527 - accuracy: 0.2883 - val_loss: 1.5357 - val_accuracy: 0.0847\nEpoch 306/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2479 - accuracy: 0.2894 - val_loss: 1.5461 - val_accuracy: 0.0822\nEpoch 307/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2505 - accuracy: 0.2883 - val_loss: 1.5328 - val_accuracy: 0.0858\nEpoch 308/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2434 - accuracy: 0.2900 - val_loss: 1.5432 - val_accuracy: 0.0858\nEpoch 309/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2478 - accuracy: 0.2889 - val_loss: 1.5512 - val_accuracy: 0.0806\nEpoch 310/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2454 - accuracy: 0.2891 - val_loss: 1.5397 - val_accuracy: 0.0824\nEpoch 311/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2429 - accuracy: 0.2893 - val_loss: 1.5372 - val_accuracy: 0.0834\nEpoch 312/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2423 - accuracy: 0.2894 - val_loss: 1.5514 - val_accuracy: 0.0830\nEpoch 313/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2454 - accuracy: 0.2889 - val_loss: 1.5567 - val_accuracy: 0.0841\nEpoch 314/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2433 - accuracy: 0.2892 - val_loss: 1.5506 - val_accuracy: 0.0824\nEpoch 315/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2401 - accuracy: 0.2895 - val_loss: 1.5454 - val_accuracy: 0.0840\nEpoch 316/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2412 - accuracy: 0.2894 - val_loss: 1.5579 - val_accuracy: 0.0822\nEpoch 317/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2412 - accuracy: 0.2893 - val_loss: 1.5519 - val_accuracy: 0.0834\nEpoch 318/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2408 - accuracy: 0.2892 - val_loss: 1.5461 - val_accuracy: 0.0846\nEpoch 319/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2359 - accuracy: 0.2900 - val_loss: 1.5466 - val_accuracy: 0.0837\nEpoch 320/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2369 - accuracy: 0.2899 - val_loss: 1.5439 - val_accuracy: 0.0873\nEpoch 321/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2403 - accuracy: 0.2897 - val_loss: 1.5387 - val_accuracy: 0.0868\nEpoch 322/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2391 - accuracy: 0.2904 - val_loss: 1.5466 - val_accuracy: 0.0854\nEpoch 323/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2334 - accuracy: 0.2908 - val_loss: 1.5410 - val_accuracy: 0.0839\nEpoch 324/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2380 - accuracy: 0.2900 - val_loss: 1.5520 - val_accuracy: 0.0844\nEpoch 325/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2369 - accuracy: 0.2903 - val_loss: 1.5502 - val_accuracy: 0.0820\nEpoch 326/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2337 - accuracy: 0.2909 - val_loss: 1.5468 - val_accuracy: 0.0835\nEpoch 327/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2401 - accuracy: 0.2894 - val_loss: 1.5369 - val_accuracy: 0.0839\nEpoch 328/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2296 - accuracy: 0.2914 - val_loss: 1.5578 - val_accuracy: 0.0821\nEpoch 329/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2344 - accuracy: 0.2908 - val_loss: 1.5501 - val_accuracy: 0.0841\nEpoch 330/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2327 - accuracy: 0.2905 - val_loss: 1.5640 - val_accuracy: 0.0824\nEpoch 331/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2317 - accuracy: 0.2905 - val_loss: 1.5484 - val_accuracy: 0.0835\nEpoch 332/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2321 - accuracy: 0.2906 - val_loss: 1.5617 - val_accuracy: 0.0835\nEpoch 333/600\n80/80 [==============================] - 2s 24ms/step - loss: 0.2342 - accuracy: 0.2903 - val_loss: 1.5571 - val_accuracy: 0.0835\nEpoch 334/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2286 - accuracy: 0.2907 - val_loss: 1.5572 - val_accuracy: 0.0825\nEpoch 335/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2324 - accuracy: 0.2910 - val_loss: 1.5468 - val_accuracy: 0.0863\nEpoch 336/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2332 - accuracy: 0.2906 - val_loss: 1.5490 - val_accuracy: 0.0849\nEpoch 337/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2267 - accuracy: 0.2914 - val_loss: 1.5675 - val_accuracy: 0.0810\nEpoch 338/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2309 - accuracy: 0.2908 - val_loss: 1.5603 - val_accuracy: 0.0818\nEpoch 339/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2281 - accuracy: 0.2914 - val_loss: 1.5586 - val_accuracy: 0.0832\nEpoch 340/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2284 - accuracy: 0.2913 - val_loss: 1.5560 - val_accuracy: 0.0839\nEpoch 341/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2287 - accuracy: 0.2914 - val_loss: 1.5578 - val_accuracy: 0.0834\nEpoch 342/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2297 - accuracy: 0.2904 - val_loss: 1.5475 - val_accuracy: 0.0842\nEpoch 343/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2250 - accuracy: 0.2918 - val_loss: 1.5520 - val_accuracy: 0.0825\nEpoch 344/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2330 - accuracy: 0.2903 - val_loss: 1.5663 - val_accuracy: 0.0813\nEpoch 345/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2252 - accuracy: 0.2918 - val_loss: 1.5540 - val_accuracy: 0.0844\nEpoch 346/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2274 - accuracy: 0.2911 - val_loss: 1.5669 - val_accuracy: 0.0823\nEpoch 347/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2241 - accuracy: 0.2917 - val_loss: 1.5685 - val_accuracy: 0.0823\nEpoch 348/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2247 - accuracy: 0.2919 - val_loss: 1.5665 - val_accuracy: 0.0806\nEpoch 349/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2231 - accuracy: 0.2920 - val_loss: 1.5627 - val_accuracy: 0.0834\nEpoch 350/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2232 - accuracy: 0.2919 - val_loss: 1.5723 - val_accuracy: 0.0827\nEpoch 351/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2270 - accuracy: 0.2912 - val_loss: 1.5459 - val_accuracy: 0.0836\nEpoch 352/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2183 - accuracy: 0.2926 - val_loss: 1.5697 - val_accuracy: 0.0838\nEpoch 353/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2219 - accuracy: 0.2919 - val_loss: 1.5481 - val_accuracy: 0.0814\nEpoch 354/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2220 - accuracy: 0.2919 - val_loss: 1.5618 - val_accuracy: 0.0845\nEpoch 355/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2213 - accuracy: 0.2922 - val_loss: 1.5616 - val_accuracy: 0.0845\nEpoch 356/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2184 - accuracy: 0.2926 - val_loss: 1.5677 - val_accuracy: 0.0835\nEpoch 357/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2226 - accuracy: 0.2917 - val_loss: 1.5608 - val_accuracy: 0.0832\nEpoch 358/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2228 - accuracy: 0.2918 - val_loss: 1.5530 - val_accuracy: 0.0849\nEpoch 359/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2185 - accuracy: 0.2920 - val_loss: 1.5684 - val_accuracy: 0.0839\nEpoch 360/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2179 - accuracy: 0.2926 - val_loss: 1.5632 - val_accuracy: 0.0844\nEpoch 361/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2222 - accuracy: 0.2915 - val_loss: 1.5680 - val_accuracy: 0.0845\nEpoch 362/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2264 - accuracy: 0.2911 - val_loss: 1.5590 - val_accuracy: 0.0844\nEpoch 363/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2180 - accuracy: 0.2927 - val_loss: 1.5758 - val_accuracy: 0.0827\nEpoch 364/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2181 - accuracy: 0.2928 - val_loss: 1.5815 - val_accuracy: 0.0823\nEpoch 365/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2210 - accuracy: 0.2919 - val_loss: 1.5636 - val_accuracy: 0.0836\nEpoch 366/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2157 - accuracy: 0.2931 - val_loss: 1.5574 - val_accuracy: 0.0850\nEpoch 367/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2124 - accuracy: 0.2933 - val_loss: 1.5451 - val_accuracy: 0.0856\nEpoch 368/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2131 - accuracy: 0.2929 - val_loss: 1.5688 - val_accuracy: 0.0832\nEpoch 369/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2151 - accuracy: 0.2930 - val_loss: 1.5643 - val_accuracy: 0.0825\nEpoch 370/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2150 - accuracy: 0.2932 - val_loss: 1.5667 - val_accuracy: 0.0836\nEpoch 371/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2143 - accuracy: 0.2929 - val_loss: 1.5644 - val_accuracy: 0.0832\nEpoch 372/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2139 - accuracy: 0.2935 - val_loss: 1.5629 - val_accuracy: 0.0850\nEpoch 373/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.2137 - accuracy: 0.2932 - val_loss: 1.5674 - val_accuracy: 0.0836\nEpoch 374/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2153 - accuracy: 0.2927 - val_loss: 1.5679 - val_accuracy: 0.0848\nEpoch 375/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2138 - accuracy: 0.2928 - val_loss: 1.5565 - val_accuracy: 0.0841\nEpoch 376/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2115 - accuracy: 0.2932 - val_loss: 1.5705 - val_accuracy: 0.0838\nEpoch 377/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2120 - accuracy: 0.2931 - val_loss: 1.5795 - val_accuracy: 0.0820\nEpoch 378/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2124 - accuracy: 0.2931 - val_loss: 1.5787 - val_accuracy: 0.0832\nEpoch 379/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2148 - accuracy: 0.2933 - val_loss: 1.5727 - val_accuracy: 0.0823\nEpoch 380/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2116 - accuracy: 0.2933 - val_loss: 1.5743 - val_accuracy: 0.0827\nEpoch 381/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2128 - accuracy: 0.2927 - val_loss: 1.5678 - val_accuracy: 0.0853\nEpoch 382/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2086 - accuracy: 0.2942 - val_loss: 1.5796 - val_accuracy: 0.0835\nEpoch 383/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2100 - accuracy: 0.2940 - val_loss: 1.5747 - val_accuracy: 0.0833\nEpoch 384/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2093 - accuracy: 0.2937 - val_loss: 1.5837 - val_accuracy: 0.0820\nEpoch 385/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2066 - accuracy: 0.2940 - val_loss: 1.5654 - val_accuracy: 0.0851\nEpoch 386/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2097 - accuracy: 0.2936 - val_loss: 1.5804 - val_accuracy: 0.0827\nEpoch 387/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2053 - accuracy: 0.2944 - val_loss: 1.5795 - val_accuracy: 0.0832\nEpoch 388/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2081 - accuracy: 0.2939 - val_loss: 1.5786 - val_accuracy: 0.0830\nEpoch 389/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2032 - accuracy: 0.2946 - val_loss: 1.5800 - val_accuracy: 0.0838\nEpoch 390/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2050 - accuracy: 0.2942 - val_loss: 1.5823 - val_accuracy: 0.0825\nEpoch 391/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2058 - accuracy: 0.2940 - val_loss: 1.5900 - val_accuracy: 0.0825\nEpoch 392/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2069 - accuracy: 0.2941 - val_loss: 1.5859 - val_accuracy: 0.0823\nEpoch 393/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2039 - accuracy: 0.2944 - val_loss: 1.5831 - val_accuracy: 0.0819\nEpoch 394/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2063 - accuracy: 0.2943 - val_loss: 1.5889 - val_accuracy: 0.0823\nEpoch 395/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2030 - accuracy: 0.2947 - val_loss: 1.5949 - val_accuracy: 0.0836\nEpoch 396/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2058 - accuracy: 0.2943 - val_loss: 1.5951 - val_accuracy: 0.0823\nEpoch 397/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2085 - accuracy: 0.2937 - val_loss: 1.5719 - val_accuracy: 0.0853\nEpoch 398/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2012 - accuracy: 0.2948 - val_loss: 1.5949 - val_accuracy: 0.0823\nEpoch 399/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2015 - accuracy: 0.2951 - val_loss: 1.5838 - val_accuracy: 0.0819\nEpoch 400/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2029 - accuracy: 0.2949 - val_loss: 1.5807 - val_accuracy: 0.0836\nEpoch 401/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.2045 - accuracy: 0.2943 - val_loss: 1.5835 - val_accuracy: 0.0840\nEpoch 402/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2046 - accuracy: 0.2945 - val_loss: 1.5746 - val_accuracy: 0.0849\nEpoch 403/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2017 - accuracy: 0.2951 - val_loss: 1.5873 - val_accuracy: 0.0816\nEpoch 404/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2037 - accuracy: 0.2945 - val_loss: 1.5860 - val_accuracy: 0.0849\nEpoch 405/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2011 - accuracy: 0.2950 - val_loss: 1.5855 - val_accuracy: 0.0824\nEpoch 406/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2017 - accuracy: 0.2951 - val_loss: 1.5793 - val_accuracy: 0.0842\nEpoch 407/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2058 - accuracy: 0.2947 - val_loss: 1.5693 - val_accuracy: 0.0849\nEpoch 408/600\n80/80 [==============================] - 2s 25ms/step - loss: 0.2010 - accuracy: 0.2954 - val_loss: 1.5786 - val_accuracy: 0.0823\nEpoch 409/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.2004 - accuracy: 0.2954 - val_loss: 1.5815 - val_accuracy: 0.0852\nEpoch 410/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1997 - accuracy: 0.2953 - val_loss: 1.5817 - val_accuracy: 0.0841\nEpoch 411/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1996 - accuracy: 0.2953 - val_loss: 1.5787 - val_accuracy: 0.0856\nEpoch 412/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1998 - accuracy: 0.2954 - val_loss: 1.5911 - val_accuracy: 0.0838\nEpoch 413/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1992 - accuracy: 0.2954 - val_loss: 1.5918 - val_accuracy: 0.0831\nEpoch 414/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1991 - accuracy: 0.2953 - val_loss: 1.5794 - val_accuracy: 0.0832\nEpoch 415/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1967 - accuracy: 0.2958 - val_loss: 1.5851 - val_accuracy: 0.0818\nEpoch 416/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1978 - accuracy: 0.2955 - val_loss: 1.5904 - val_accuracy: 0.0856\nEpoch 417/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1964 - accuracy: 0.2955 - val_loss: 1.5938 - val_accuracy: 0.0844\nEpoch 418/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1959 - accuracy: 0.2958 - val_loss: 1.5946 - val_accuracy: 0.0820\nEpoch 419/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.2027 - accuracy: 0.2947 - val_loss: 1.5876 - val_accuracy: 0.0825\nEpoch 420/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1954 - accuracy: 0.2957 - val_loss: 1.6002 - val_accuracy: 0.0810\nEpoch 421/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1962 - accuracy: 0.2958 - val_loss: 1.5949 - val_accuracy: 0.0825\nEpoch 422/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1945 - accuracy: 0.2960 - val_loss: 1.5876 - val_accuracy: 0.0844\nEpoch 423/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1945 - accuracy: 0.2961 - val_loss: 1.6039 - val_accuracy: 0.0811\nEpoch 424/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1949 - accuracy: 0.2961 - val_loss: 1.5774 - val_accuracy: 0.0823\nEpoch 425/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1980 - accuracy: 0.2953 - val_loss: 1.5905 - val_accuracy: 0.0835\nEpoch 426/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1935 - accuracy: 0.2963 - val_loss: 1.5882 - val_accuracy: 0.0834\nEpoch 427/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1940 - accuracy: 0.2960 - val_loss: 1.5805 - val_accuracy: 0.0828\nEpoch 428/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1945 - accuracy: 0.2964 - val_loss: 1.5829 - val_accuracy: 0.0851\nEpoch 429/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1922 - accuracy: 0.2965 - val_loss: 1.5915 - val_accuracy: 0.0839\nEpoch 430/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1924 - accuracy: 0.2964 - val_loss: 1.5881 - val_accuracy: 0.0831\nEpoch 431/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1922 - accuracy: 0.2969 - val_loss: 1.5923 - val_accuracy: 0.0861\nEpoch 432/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1921 - accuracy: 0.2967 - val_loss: 1.6018 - val_accuracy: 0.0839\nEpoch 433/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1938 - accuracy: 0.2961 - val_loss: 1.6030 - val_accuracy: 0.0827\nEpoch 434/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1901 - accuracy: 0.2967 - val_loss: 1.6008 - val_accuracy: 0.0846\nEpoch 435/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1890 - accuracy: 0.2970 - val_loss: 1.6117 - val_accuracy: 0.0832\nEpoch 436/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1888 - accuracy: 0.2967 - val_loss: 1.5977 - val_accuracy: 0.0832\nEpoch 437/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1897 - accuracy: 0.2966 - val_loss: 1.5908 - val_accuracy: 0.0827\nEpoch 438/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1874 - accuracy: 0.2967 - val_loss: 1.5950 - val_accuracy: 0.0845\nEpoch 439/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1895 - accuracy: 0.2969 - val_loss: 1.5918 - val_accuracy: 0.0830\nEpoch 440/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1896 - accuracy: 0.2968 - val_loss: 1.6013 - val_accuracy: 0.0830\nEpoch 441/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1852 - accuracy: 0.2974 - val_loss: 1.5902 - val_accuracy: 0.0842\nEpoch 442/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1904 - accuracy: 0.2969 - val_loss: 1.6064 - val_accuracy: 0.0836\nEpoch 443/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1868 - accuracy: 0.2975 - val_loss: 1.6037 - val_accuracy: 0.0837\nEpoch 444/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1871 - accuracy: 0.2972 - val_loss: 1.6102 - val_accuracy: 0.0830\nEpoch 445/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1895 - accuracy: 0.2967 - val_loss: 1.6104 - val_accuracy: 0.0815\nEpoch 446/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1849 - accuracy: 0.2975 - val_loss: 1.6114 - val_accuracy: 0.0842\nEpoch 447/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1876 - accuracy: 0.2971 - val_loss: 1.6050 - val_accuracy: 0.0858\nEpoch 448/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1842 - accuracy: 0.2973 - val_loss: 1.6035 - val_accuracy: 0.0832\nEpoch 449/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1844 - accuracy: 0.2973 - val_loss: 1.6052 - val_accuracy: 0.0834\nEpoch 450/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1881 - accuracy: 0.2969 - val_loss: 1.6044 - val_accuracy: 0.0838\nEpoch 451/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1873 - accuracy: 0.2970 - val_loss: 1.5946 - val_accuracy: 0.0821\nEpoch 452/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1863 - accuracy: 0.2973 - val_loss: 1.6031 - val_accuracy: 0.0849\nEpoch 453/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1832 - accuracy: 0.2975 - val_loss: 1.6146 - val_accuracy: 0.0815\nEpoch 454/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1871 - accuracy: 0.2968 - val_loss: 1.5993 - val_accuracy: 0.0849\nEpoch 455/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1846 - accuracy: 0.2970 - val_loss: 1.6092 - val_accuracy: 0.0842\nEpoch 456/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1870 - accuracy: 0.2968 - val_loss: 1.6021 - val_accuracy: 0.0834\nEpoch 457/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1838 - accuracy: 0.2972 - val_loss: 1.6088 - val_accuracy: 0.0814\nEpoch 458/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1853 - accuracy: 0.2974 - val_loss: 1.6183 - val_accuracy: 0.0837\nEpoch 459/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1851 - accuracy: 0.2971 - val_loss: 1.6131 - val_accuracy: 0.0833\nEpoch 460/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1831 - accuracy: 0.2977 - val_loss: 1.6102 - val_accuracy: 0.0861\nEpoch 461/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1836 - accuracy: 0.2976 - val_loss: 1.6177 - val_accuracy: 0.0822\nEpoch 462/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1822 - accuracy: 0.2977 - val_loss: 1.6167 - val_accuracy: 0.0805\nEpoch 463/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1851 - accuracy: 0.2972 - val_loss: 1.6086 - val_accuracy: 0.0820\nEpoch 464/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1831 - accuracy: 0.2978 - val_loss: 1.6143 - val_accuracy: 0.0839\nEpoch 465/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1818 - accuracy: 0.2978 - val_loss: 1.6074 - val_accuracy: 0.0840\nEpoch 466/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1825 - accuracy: 0.2974 - val_loss: 1.6067 - val_accuracy: 0.0858\nEpoch 467/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1824 - accuracy: 0.2978 - val_loss: 1.6132 - val_accuracy: 0.0825\nEpoch 468/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1818 - accuracy: 0.2976 - val_loss: 1.6062 - val_accuracy: 0.0845\nEpoch 469/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1815 - accuracy: 0.2978 - val_loss: 1.6149 - val_accuracy: 0.0837\nEpoch 470/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1818 - accuracy: 0.2977 - val_loss: 1.6107 - val_accuracy: 0.0830\nEpoch 471/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1802 - accuracy: 0.2979 - val_loss: 1.6203 - val_accuracy: 0.0830\nEpoch 472/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1811 - accuracy: 0.2979 - val_loss: 1.6134 - val_accuracy: 0.0835\nEpoch 473/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1799 - accuracy: 0.2980 - val_loss: 1.6225 - val_accuracy: 0.0827\nEpoch 474/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1806 - accuracy: 0.2977 - val_loss: 1.6079 - val_accuracy: 0.0839\nEpoch 475/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1822 - accuracy: 0.2975 - val_loss: 1.6110 - val_accuracy: 0.0823\nEpoch 476/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1857 - accuracy: 0.2969 - val_loss: 1.6173 - val_accuracy: 0.0813\nEpoch 477/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1818 - accuracy: 0.2974 - val_loss: 1.6146 - val_accuracy: 0.0842\nEpoch 478/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1804 - accuracy: 0.2977 - val_loss: 1.6101 - val_accuracy: 0.0816\nEpoch 479/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1796 - accuracy: 0.2982 - val_loss: 1.6261 - val_accuracy: 0.0822\nEpoch 480/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1792 - accuracy: 0.2981 - val_loss: 1.5932 - val_accuracy: 0.0846\nEpoch 481/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1799 - accuracy: 0.2977 - val_loss: 1.6063 - val_accuracy: 0.0851\nEpoch 482/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1834 - accuracy: 0.2975 - val_loss: 1.6177 - val_accuracy: 0.0825\nEpoch 483/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1788 - accuracy: 0.2978 - val_loss: 1.6268 - val_accuracy: 0.0826\nEpoch 484/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1763 - accuracy: 0.2984 - val_loss: 1.6125 - val_accuracy: 0.0835\nEpoch 485/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1776 - accuracy: 0.2984 - val_loss: 1.6108 - val_accuracy: 0.0829\nEpoch 486/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1756 - accuracy: 0.2985 - val_loss: 1.6161 - val_accuracy: 0.0840\nEpoch 487/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1770 - accuracy: 0.2983 - val_loss: 1.6100 - val_accuracy: 0.0809\nEpoch 488/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1787 - accuracy: 0.2980 - val_loss: 1.6046 - val_accuracy: 0.0849\nEpoch 489/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1751 - accuracy: 0.2984 - val_loss: 1.6105 - val_accuracy: 0.0852\nEpoch 490/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1770 - accuracy: 0.2983 - val_loss: 1.6167 - val_accuracy: 0.0833\nEpoch 491/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1765 - accuracy: 0.2982 - val_loss: 1.6247 - val_accuracy: 0.0832\nEpoch 492/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1804 - accuracy: 0.2976 - val_loss: 1.6200 - val_accuracy: 0.0819\nEpoch 493/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1763 - accuracy: 0.2984 - val_loss: 1.6326 - val_accuracy: 0.0804\nEpoch 494/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1726 - accuracy: 0.2987 - val_loss: 1.6365 - val_accuracy: 0.0801\nEpoch 495/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1782 - accuracy: 0.2981 - val_loss: 1.6324 - val_accuracy: 0.0809\nEpoch 496/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1819 - accuracy: 0.2972 - val_loss: 1.6235 - val_accuracy: 0.0818\nEpoch 497/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1751 - accuracy: 0.2986 - val_loss: 1.6257 - val_accuracy: 0.0808\nEpoch 498/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1747 - accuracy: 0.2987 - val_loss: 1.6153 - val_accuracy: 0.0818\nEpoch 499/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1779 - accuracy: 0.2984 - val_loss: 1.6091 - val_accuracy: 0.0841\nEpoch 500/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1797 - accuracy: 0.2977 - val_loss: 1.6384 - val_accuracy: 0.0797\nEpoch 501/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1759 - accuracy: 0.2981 - val_loss: 1.6329 - val_accuracy: 0.0809\nEpoch 502/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1734 - accuracy: 0.2990 - val_loss: 1.6268 - val_accuracy: 0.0812\nEpoch 503/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1765 - accuracy: 0.2983 - val_loss: 1.6250 - val_accuracy: 0.0845\nEpoch 504/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1744 - accuracy: 0.2988 - val_loss: 1.6221 - val_accuracy: 0.0811\nEpoch 505/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1764 - accuracy: 0.2985 - val_loss: 1.6398 - val_accuracy: 0.0804\nEpoch 506/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1734 - accuracy: 0.2990 - val_loss: 1.6382 - val_accuracy: 0.0808\nEpoch 507/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1736 - accuracy: 0.2988 - val_loss: 1.6305 - val_accuracy: 0.0835\nEpoch 508/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1727 - accuracy: 0.2987 - val_loss: 1.6295 - val_accuracy: 0.0814\nEpoch 509/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1743 - accuracy: 0.2987 - val_loss: 1.6393 - val_accuracy: 0.0799\nEpoch 510/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1778 - accuracy: 0.2978 - val_loss: 1.6334 - val_accuracy: 0.0832\nEpoch 511/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1730 - accuracy: 0.2988 - val_loss: 1.6175 - val_accuracy: 0.0826\nEpoch 512/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1764 - accuracy: 0.2985 - val_loss: 1.6407 - val_accuracy: 0.0815\nEpoch 513/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1704 - accuracy: 0.2992 - val_loss: 1.6191 - val_accuracy: 0.0841\nEpoch 514/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1709 - accuracy: 0.2992 - val_loss: 1.6338 - val_accuracy: 0.0821\nEpoch 515/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1740 - accuracy: 0.2987 - val_loss: 1.6244 - val_accuracy: 0.0815\nEpoch 516/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1706 - accuracy: 0.2993 - val_loss: 1.6168 - val_accuracy: 0.0837\nEpoch 517/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1719 - accuracy: 0.2991 - val_loss: 1.6254 - val_accuracy: 0.0823\nEpoch 518/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1709 - accuracy: 0.2992 - val_loss: 1.6270 - val_accuracy: 0.0819\nEpoch 519/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1729 - accuracy: 0.2987 - val_loss: 1.6278 - val_accuracy: 0.0833\nEpoch 520/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1735 - accuracy: 0.2986 - val_loss: 1.6266 - val_accuracy: 0.0832\nEpoch 521/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1725 - accuracy: 0.2990 - val_loss: 1.6213 - val_accuracy: 0.0825\nEpoch 522/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1730 - accuracy: 0.2987 - val_loss: 1.6200 - val_accuracy: 0.0835\nEpoch 523/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1706 - accuracy: 0.2993 - val_loss: 1.6353 - val_accuracy: 0.0824\nEpoch 524/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1709 - accuracy: 0.2995 - val_loss: 1.6175 - val_accuracy: 0.0837\nEpoch 525/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1727 - accuracy: 0.2993 - val_loss: 1.6239 - val_accuracy: 0.0848\nEpoch 526/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1711 - accuracy: 0.2993 - val_loss: 1.6226 - val_accuracy: 0.0820\nEpoch 527/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1699 - accuracy: 0.2995 - val_loss: 1.6216 - val_accuracy: 0.0830\nEpoch 528/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1687 - accuracy: 0.2999 - val_loss: 1.6254 - val_accuracy: 0.0877\nEpoch 529/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1702 - accuracy: 0.2994 - val_loss: 1.6235 - val_accuracy: 0.0837\nEpoch 530/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1688 - accuracy: 0.2998 - val_loss: 1.6302 - val_accuracy: 0.0829\nEpoch 531/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1768 - accuracy: 0.2987 - val_loss: 1.6382 - val_accuracy: 0.0820\nEpoch 532/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1686 - accuracy: 0.2996 - val_loss: 1.6269 - val_accuracy: 0.0832\nEpoch 533/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1679 - accuracy: 0.2996 - val_loss: 1.6272 - val_accuracy: 0.0839\nEpoch 534/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1699 - accuracy: 0.2991 - val_loss: 1.6293 - val_accuracy: 0.0854\nEpoch 535/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1693 - accuracy: 0.2996 - val_loss: 1.6249 - val_accuracy: 0.0831\nEpoch 536/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1676 - accuracy: 0.2996 - val_loss: 1.6306 - val_accuracy: 0.0831\nEpoch 537/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1683 - accuracy: 0.2995 - val_loss: 1.6322 - val_accuracy: 0.0840\nEpoch 538/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1693 - accuracy: 0.2992 - val_loss: 1.6311 - val_accuracy: 0.0849\nEpoch 539/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1665 - accuracy: 0.2998 - val_loss: 1.6254 - val_accuracy: 0.0842\nEpoch 540/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1677 - accuracy: 0.2996 - val_loss: 1.6320 - val_accuracy: 0.0839\nEpoch 541/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1658 - accuracy: 0.2997 - val_loss: 1.6304 - val_accuracy: 0.0825\nEpoch 542/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1730 - accuracy: 0.2987 - val_loss: 1.6352 - val_accuracy: 0.0823\nEpoch 543/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1728 - accuracy: 0.2987 - val_loss: 1.6272 - val_accuracy: 0.0837\nEpoch 544/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1664 - accuracy: 0.2998 - val_loss: 1.6345 - val_accuracy: 0.0827\nEpoch 545/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1669 - accuracy: 0.2995 - val_loss: 1.6287 - val_accuracy: 0.0841\nEpoch 546/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1663 - accuracy: 0.2998 - val_loss: 1.6345 - val_accuracy: 0.0842\nEpoch 547/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1684 - accuracy: 0.2999 - val_loss: 1.6109 - val_accuracy: 0.0840\nEpoch 548/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1638 - accuracy: 0.3002 - val_loss: 1.6223 - val_accuracy: 0.0825\nEpoch 549/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1654 - accuracy: 0.2998 - val_loss: 1.6642 - val_accuracy: 0.0801\nEpoch 550/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1725 - accuracy: 0.2989 - val_loss: 1.6371 - val_accuracy: 0.0804\nEpoch 551/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1643 - accuracy: 0.3000 - val_loss: 1.6435 - val_accuracy: 0.0815\nEpoch 552/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1645 - accuracy: 0.3004 - val_loss: 1.6242 - val_accuracy: 0.0846\nEpoch 553/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1695 - accuracy: 0.2997 - val_loss: 1.6343 - val_accuracy: 0.0829\nEpoch 554/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1692 - accuracy: 0.2994 - val_loss: 1.6263 - val_accuracy: 0.0840\nEpoch 555/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1648 - accuracy: 0.3001 - val_loss: 1.6406 - val_accuracy: 0.0821\nEpoch 556/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1654 - accuracy: 0.2998 - val_loss: 1.6382 - val_accuracy: 0.0825\nEpoch 557/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1641 - accuracy: 0.3002 - val_loss: 1.6329 - val_accuracy: 0.0835\nEpoch 558/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1657 - accuracy: 0.3005 - val_loss: 1.6465 - val_accuracy: 0.0811\nEpoch 559/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1646 - accuracy: 0.2998 - val_loss: 1.6528 - val_accuracy: 0.0818\nEpoch 560/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1659 - accuracy: 0.2999 - val_loss: 1.6519 - val_accuracy: 0.0806\nEpoch 561/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1631 - accuracy: 0.3005 - val_loss: 1.6464 - val_accuracy: 0.0806\nEpoch 562/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1653 - accuracy: 0.2999 - val_loss: 1.6475 - val_accuracy: 0.0811\nEpoch 563/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1717 - accuracy: 0.2989 - val_loss: 1.6442 - val_accuracy: 0.0829\nEpoch 564/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1638 - accuracy: 0.3003 - val_loss: 1.6420 - val_accuracy: 0.0834\nEpoch 565/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1642 - accuracy: 0.3000 - val_loss: 1.6588 - val_accuracy: 0.0820\nEpoch 566/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1661 - accuracy: 0.3001 - val_loss: 1.6478 - val_accuracy: 0.0829\nEpoch 567/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1648 - accuracy: 0.3001 - val_loss: 1.6418 - val_accuracy: 0.0811\nEpoch 568/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1654 - accuracy: 0.3000 - val_loss: 1.6487 - val_accuracy: 0.0834\nEpoch 569/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1627 - accuracy: 0.3008 - val_loss: 1.6365 - val_accuracy: 0.0837\nEpoch 570/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1615 - accuracy: 0.3006 - val_loss: 1.6595 - val_accuracy: 0.0831\nEpoch 571/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1649 - accuracy: 0.2999 - val_loss: 1.6501 - val_accuracy: 0.0821\nEpoch 572/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1635 - accuracy: 0.2998 - val_loss: 1.6503 - val_accuracy: 0.0827\nEpoch 573/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1621 - accuracy: 0.3005 - val_loss: 1.6382 - val_accuracy: 0.0835\nEpoch 574/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1652 - accuracy: 0.2996 - val_loss: 1.6528 - val_accuracy: 0.0832\nEpoch 575/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1619 - accuracy: 0.3006 - val_loss: 1.6384 - val_accuracy: 0.0836\nEpoch 576/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1626 - accuracy: 0.3007 - val_loss: 1.6519 - val_accuracy: 0.0830\nEpoch 577/600\n80/80 [==============================] - 2s 26ms/step - loss: 0.1667 - accuracy: 0.2997 - val_loss: 1.6556 - val_accuracy: 0.0808\nEpoch 578/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1628 - accuracy: 0.3003 - val_loss: 1.6621 - val_accuracy: 0.0827\nEpoch 579/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1610 - accuracy: 0.3009 - val_loss: 1.6538 - val_accuracy: 0.0832\nEpoch 580/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1608 - accuracy: 0.3005 - val_loss: 1.6573 - val_accuracy: 0.0832\nEpoch 581/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1626 - accuracy: 0.3005 - val_loss: 1.6402 - val_accuracy: 0.0824\nEpoch 582/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1642 - accuracy: 0.2999 - val_loss: 1.6608 - val_accuracy: 0.0804\nEpoch 583/600\n80/80 [==============================] - 2s 23ms/step - loss: 0.1621 - accuracy: 0.3004 - val_loss: 1.6578 - val_accuracy: 0.0816\nEpoch 584/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1667 - accuracy: 0.2992 - val_loss: 1.6556 - val_accuracy: 0.0816\nEpoch 585/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1651 - accuracy: 0.3000 - val_loss: 1.6569 - val_accuracy: 0.0813\nEpoch 586/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1607 - accuracy: 0.3005 - val_loss: 1.6457 - val_accuracy: 0.0837\nEpoch 587/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1606 - accuracy: 0.3007 - val_loss: 1.6451 - val_accuracy: 0.0811\nEpoch 588/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1607 - accuracy: 0.3008 - val_loss: 1.6562 - val_accuracy: 0.0823\nEpoch 589/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1606 - accuracy: 0.3008 - val_loss: 1.6573 - val_accuracy: 0.0825\nEpoch 590/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1614 - accuracy: 0.3004 - val_loss: 1.6562 - val_accuracy: 0.0813\nEpoch 591/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1580 - accuracy: 0.3010 - val_loss: 1.6508 - val_accuracy: 0.0815\nEpoch 592/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1589 - accuracy: 0.3007 - val_loss: 1.6484 - val_accuracy: 0.0808\nEpoch 593/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1634 - accuracy: 0.2997 - val_loss: 1.6488 - val_accuracy: 0.0813\nEpoch 594/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1587 - accuracy: 0.3010 - val_loss: 1.6434 - val_accuracy: 0.0804\nEpoch 595/600\n80/80 [==============================] - 2s 24ms/step - loss: 0.1591 - accuracy: 0.3007 - val_loss: 1.6469 - val_accuracy: 0.0822\nEpoch 596/600\n80/80 [==============================] - 2s 21ms/step - loss: 0.1620 - accuracy: 0.3003 - val_loss: 1.6461 - val_accuracy: 0.0816\nEpoch 597/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1579 - accuracy: 0.3007 - val_loss: 1.6405 - val_accuracy: 0.0846\nEpoch 598/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1593 - accuracy: 0.3009 - val_loss: 1.6463 - val_accuracy: 0.0830\nEpoch 599/600\n80/80 [==============================] - 2s 20ms/step - loss: 0.1609 - accuracy: 0.3006 - val_loss: 1.6378 - val_accuracy: 0.0830\nEpoch 600/600\n80/80 [==============================] - 2s 22ms/step - loss: 0.1565 - accuracy: 0.3013 - val_loss: 1.6481 - val_accuracy: 0.0823\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7efed3b35610>"},"metadata":{}}]},{"cell_type":"code","source":"training_model.save('training_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:40:19.457620Z","iopub.execute_input":"2022-12-23T09:40:19.457958Z","iopub.status.idle":"2022-12-23T09:40:19.525417Z","shell.execute_reply.started":"2022-12-23T09:40:19.457931Z","shell.execute_reply":"2022-12-23T09:40:19.524135Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tf.config.list_physical_devices()","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:40:19.527100Z","iopub.execute_input":"2022-12-23T09:40:19.527511Z","iopub.status.idle":"2022-12-23T09:40:19.535455Z","shell.execute_reply.started":"2022-12-23T09:40:19.527470Z","shell.execute_reply":"2022-12-23T09:40:19.534283Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"},"metadata":{}}]},{"cell_type":"code","source":"from keras.models import load_model\ntraining_model = load_model('training_model.h5')\nencoder_inputs = training_model.input[0]\nencoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\nencoder_states = [state_h_enc, state_c_enc]\nencoder_model = Model(encoder_inputs, encoder_states)\n\nlatent_dim = 256\ndecoder_state_input_hidden = Input(shape=(latent_dim,))\ndecoder_state_input_cell = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\ndecoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\ndecoder_states = [state_hidden, state_cell]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n\ndef decode_response(test_input):\n    states_value = encoder_model.predict(test_input)\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    target_seq[0, 0, target_features_dict['<START>']] = 1.\n    \n    decoded_sentence = ''\n\n    stop_condition = False\n    \n    while not stop_condition:\n        output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = reverse_target_features_dict[sampled_token_index]\n        decoded_sentence += \" \" + sampled_token\n\n        if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n            stop_condition = True\n        target_seq = np.zeros((1, 1, num_decoder_tokens))\n        target_seq[0, 0, sampled_token_index] = 1.\n        states_value = [hidden_state, cell_state]\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:40:19.537285Z","iopub.execute_input":"2022-12-23T09:40:19.538161Z","iopub.status.idle":"2022-12-23T09:40:20.239625Z","shell.execute_reply.started":"2022-12-23T09:40:19.538124Z","shell.execute_reply":"2022-12-23T09:40:20.238603Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"name = \"100557155\"\n\ntestQuestions = [\n    \"Hello\",\n    \"since updating I am unable to use mail becuase of a bug with the I key\",\n    \"I have been trying to conact the call centres what time are they open?\",\n    \"I need to upgrade my phone because my battery life is bad\",\n    \"After I upgraded my phone, I am unable to get past the lock screen\",\n    \"I cannot use my home button for some reason, please help\",\n    \"@AppleSupport The newest update. I️ made sure to download it yesterday\", #this question is directly copied from dataset\n    \"Thanks for helping me out!\",\n    \"bye\"\n    \n]\nclass ChatBot:\n    negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n    exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n    def start_chat(self):\n    for q in testQuestions:\n        print(name + \": \" + q)\n        print(\"BOT: \" + self.generate_response(q))\n    \n    def chat(self, reply):\n        while not self.make_exit(reply):\n        reply = input(self.generate_response(reply)+\"\\n\")\n    \n    def string_to_matrix(self, user_input):    \n        tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n        user_input_matrix = np.zeros((1, max_encoder_seq_length, num_encoder_tokens),dtype='float32')\n        for timestep, token in enumerate(tokens):\n            if token in input_features_dict:\n                user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n    return user_input_matrix\n  \n    def generate_response(self, user_input):\n        input_matrix = self.string_to_matrix(user_input)\n        chatbot_response = decode_response(input_matrix)\n        chatbot_response = chatbot_response.replace(\"<START>\",'')\n        chatbot_response = chatbot_response.replace(\"<END>\",'')\n    return chatbot_response\n\n    def make_exit(self, reply):\n        for exit_command in self.exit_commands:\n            if exit_command in reply:\n                print(\"Ok, have a great day!\")\n                return True\n        return False\n  \nchatbot = ChatBot()\nchatbot.start_chat()","metadata":{"execution":{"iopub.status.busy":"2022-12-23T09:40:20.241205Z","iopub.execute_input":"2022-12-23T09:40:20.241574Z","iopub.status.idle":"2022-12-23T09:40:27.602085Z","shell.execute_reply.started":"2022-12-23T09:40:20.241537Z","shell.execute_reply":"2022-12-23T09:40:27.601102Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"100557155: Hello\nBOT:  We've received your DM and will continue there . . . . . . . . . . . . .\n100557155: since updating I am unable to use mail becuase of a bug with the I key\nBOT:  We can help ! What happens after it says verifying . Is that when it restarts\n100557155: I have been trying to conact the call centres what time are they open?\nBOT:  We want to help you . That station may not be available . Availability of\n100557155: I need to upgrade my phone because my battery life is bad\nBOT:  We want to help you . That station may not be available . Availability of\n100557155: After I upgraded my phone, I am unable to get past the lock screen\nBOT:  Send us a DM and we'll continue there . . . . . . . . . . . . . . . . .\n100557155: I cannot use my home button for some reason, please help\nBOT:  If you're still having troubles , be sure to follow up with our team that\n100557155: @AppleSupport The newest update. I️ made sure to download it yesterday\nBOT:  We're here to help . Which version of iOS device are you currently running\n100557155: Thanks for helping me out!\nBOT:  We've gotten your DM and will continue there there . . . . . . . . . . .\n100557155: bye\nBOT:  Let's work together to figure out the best path forward with your new iPod\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}